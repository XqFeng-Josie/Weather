"""
æ‰©æ•£æ¨¡å‹é¢„æµ‹è„šæœ¬ - æ¦‚ç‡å¼å¤©æ°”é¢„æµ‹

ğŸ“‹ æ–‡ä»¶ä½œç”¨:
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¦‚ç‡å¼é¢„æµ‹ï¼Œé€šè¿‡é‡‡æ ·ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„æœªæ¥çŠ¶æ€ã€‚
    
ğŸ”„ é¢„æµ‹æµç¨‹:
    1. åŠ è½½è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹å’Œé…ç½®
    2. åŠ è½½VAEæ¨¡å‹
    3. åŠ è½½æµ‹è¯•æ•°æ®
    4. VAEåˆ†æ‰¹ç¼–ç è¾“å…¥åºåˆ—åˆ°æ½œç©ºé—´
    5. ä»çº¯å™ªå£°å¼€å§‹ï¼Œé€æ­¥å»å™ªç”Ÿæˆé¢„æµ‹ï¼ˆDDPM/DDIMé‡‡æ ·ï¼‰
    6. VAEåˆ†æ‰¹è§£ç å›åƒç´ ç©ºé—´
    7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå•æ¬¡é¢„æµ‹ + é›†æˆé¢„æµ‹ï¼‰
    8. ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ—¶é—´åºåˆ—å›¾ + ä¸–ç•Œåœ°å›¾å¯¹æ¯” + ä¸ç¡®å®šæ€§å›¾ï¼‰
    9. ä¿å­˜æ‰€æœ‰ç»“æœ
    
âš¡ æ˜¾å­˜ä¼˜åŒ–:
    - VAEåˆ†æ‰¹ç¼–ç /è§£ç ï¼ˆä¸train_diffusion.pyä¸€è‡´ï¼‰
    - æ”¯æŒå¤šæ¬¡é‡‡æ ·ç”Ÿæˆé›†æˆé¢„æµ‹
    - é»˜è®¤vae_batch_size=4ï¼Œé€‚åˆ12GB GPU
    
ğŸ“Š è¾“å‡ºæ–‡ä»¶:
    - prediction_metrics.json: è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
    - y_pred_*.npy: é¢„æµ‹æ•°æ®
    - y_true_*.npy: çœŸå€¼æ•°æ®
    - ensemble_*.npy: é›†æˆé¢„æµ‹æ•°æ®ï¼ˆå¦‚æœnum_samples>1ï¼‰
    - timeseries_*.png: æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
    - spatial_comparison_*.png: ä¸–ç•Œåœ°å›¾å¯¹æ¯”å›¾
    - uncertainty_*.png: é¢„æµ‹ä¸ç¡®å®šæ€§å›¾ï¼ˆé›†æˆé¢„æµ‹ï¼‰
    
ğŸ“– ä½¿ç”¨æ–¹æ³•:
    # å•æ¬¡é¢„æµ‹
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --time-slice 2020-01-01:2020-12-31 \\
        --vae-batch-size 4
    
    # é›†æˆé¢„æµ‹ï¼ˆç”Ÿæˆå¤šä¸ªæ ·æœ¬ï¼‰
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --time-slice 2020-01-01:2020-12-31 \\
        --num-samples 10 \\
        --vae-batch-size 4
    
    # ä½¿ç”¨DDIMé‡‡æ ·ï¼ˆæ›´å¿«ï¼‰
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --sampling-method ddim \\
        --num-inference-steps 50

ğŸ¯ é¢„æœŸæ•ˆæœ:
    å•æ¬¡é¢„æµ‹:
        - RMSE: 3-6K
        - ç›¸å…³ç³»æ•°: > 0.98
        - SSIM: > 0.98
    
    é›†æˆé¢„æµ‹:
        - RMSE: 2-4K (é›†æˆåæ›´å‡†ç¡®)
        - æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡
"""

import argparse
import torch
import numpy as np
import json
import pickle
from pathlib import Path
from tqdm import tqdm

from weatherdiff.diffusion import WeatherDiffusion, DDPMScheduler
from weatherdiff.vae import SDVAEWrapper
from weatherdiff.utils import WeatherDataModule, calculate_metrics, format_metrics
from src.visualization import visualize_predictions_improved


def encode_in_batches(vae_wrapper, images, vae_batch_size=4, device='cuda'):
    """
    åˆ†æ‰¹ç¼–ç å›¾åƒåˆ°æ½œç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    
    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        images: (N, C, H, W) å›¾åƒtensor
        vae_batch_size: VAEç¼–ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
    
    Returns:
        latents: (N, 4, H//8, W//8) æ½œå‘é‡
    """
    N = images.shape[0]
    latent_list = []
    
    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = images[i:end_idx].to(device)
        latent_batch = vae_wrapper.encode(batch)
        latent_list.append(latent_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜
        
        # æ¸…ç†æ˜¾å­˜
        del batch, latent_batch
        torch.cuda.empty_cache()
    
    # åˆå¹¶æ‰€æœ‰batch
    latents = torch.cat(latent_list, dim=0).to(device)
    return latents


def decode_in_batches(vae_wrapper, latents, vae_batch_size=4, device='cuda'):
    """
    åˆ†æ‰¹è§£ç æ½œå‘é‡åˆ°åƒç´ ç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    
    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        latents: (N, 4, H//8, W//8) æ½œå‘é‡tensor
        vae_batch_size: VAEè§£ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
    
    Returns:
        images: (N, 3, H, W) å›¾åƒ
    """
    N = latents.shape[0]
    image_list = []
    
    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = latents[i:end_idx].to(device)
        image_batch = vae_wrapper.decode(batch)
        image_list.append(image_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜
        
        # æ¸…ç†æ˜¾å­˜
        del batch, image_batch
        torch.cuda.empty_cache()
    
    # åˆå¹¶æ‰€æœ‰batch
    images = torch.cat(image_list, dim=0).to(device)
    return images


def ddpm_sample(model, condition, latent_shape, scheduler, device, num_inference_steps=None):
    """
    DDPMé‡‡æ ·ï¼ˆé€æ­¥å»å™ªï¼‰
    
    Args:
        model: æ‰©æ•£æ¨¡å‹
        condition: æ¡ä»¶ï¼ˆè¾“å…¥åºåˆ—çš„æ½œå‘é‡ï¼‰
        latent_shape: æ½œå‘é‡å½¢çŠ¶ (B, T_out, 4, H//8, W//8)
        scheduler: DDPMè°ƒåº¦å™¨
        device: è®¾å¤‡
        num_inference_steps: æ¨ç†æ­¥æ•°ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ­¥æ•°ï¼‰
    
    Returns:
        samples: é‡‡æ ·ç»“æœ (B, T_out, 4, H//8, W//8)
    """
    # ä»çº¯å™ªå£°å¼€å§‹
    latent = torch.randn(latent_shape, device=device)
    
    # è®¾ç½®æ¨ç†æ­¥æ•°
    if num_inference_steps is None:
        num_inference_steps = scheduler.num_train_timesteps
    
    timesteps = torch.linspace(scheduler.num_train_timesteps - 1, 0, num_inference_steps, dtype=torch.long, device=device)
    
    # é€æ­¥å»å™ª
    for t in tqdm(timesteps, desc='DDPMé‡‡æ ·'):
        with torch.no_grad():
            # é¢„æµ‹å™ªå£°
            noise_pred = model(latent, t.unsqueeze(0).expand(latent_shape[0]), condition)
            
            # å»å™ªä¸€æ­¥
            latent = scheduler.step(noise_pred, t, latent)
    
    return latent


def main():
    parser = argparse.ArgumentParser(description='æ‰©æ•£æ¨¡å‹é¢„æµ‹')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model-dir', type=str, default='outputs/diffusion',
                       help='æ¨¡å‹ç›®å½•ï¼ˆåŒ…å«best_model.ptå’Œconfig.jsonï¼‰')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data-path', type=str,
                       default='gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr',
                       help='æ•°æ®è·¯å¾„')
    parser.add_argument('--time-slice', type=str, default='2020-01-01:2020-12-31',
                       help='é¢„æµ‹æ—¶é—´èŒƒå›´')
    
    # é‡‡æ ·å‚æ•°
    parser.add_argument('--sampling-method', type=str, default='ddpm',
                       choices=['ddpm', 'ddim'],
                       help='é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--num-inference-steps', type=int, default=None,
                       help='æ¨ç†æ­¥æ•°ï¼ˆNone=ä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ­¥æ•°ï¼‰')
    parser.add_argument('--num-samples', type=int, default=1,
                       help='æ¯ä¸ªè¾“å…¥ç”Ÿæˆçš„æ ·æœ¬æ•°ï¼ˆç”¨äºé›†æˆé¢„æµ‹ï¼‰')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹ç›®å½•ï¼‰')
    parser.add_argument('--batch-size', type=int, default=16,
                       help='é¢„æµ‹æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--vae-batch-size', type=int, default=4,
                       help='VAEç¼–ç /è§£ç æ‰¹æ¬¡å¤§å°ï¼ˆæ§åˆ¶æ˜¾å­˜å ç”¨ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str,
                       default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='è®¾å¤‡')
    
    args = parser.parse_args()
    
    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "=" * 80)
    print("æ‰©æ•£æ¨¡å‹é¢„æµ‹ - æ¦‚ç‡å¼å¤©æ°”é¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"æ ·æœ¬æ•°: {args.num_samples}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)
    
    config_path = model_dir / 'config.json'
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")
    print(f"  VAEæ¨¡å‹: {config['vae_model_id']}")
    
    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / 'normalizer_stats.pkl'
    with open(normalizer_path, 'rb') as f:
        normalizer_data = pickle.load(f)
    
    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")
    
    # ========================================================================
    # Step 2: åŠ è½½VAE
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½VAE")
    print("-" * 80)
    
    vae_wrapper = SDVAEWrapper(
        model_id=config['vae_model_id'],
        device=args.device
    )
    print(f"âœ“ VAEåŠ è½½å®Œæˆ")
    
    # ========================================================================
    # Step 3: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ•°æ®")
    print("-" * 80)
    
    target_size = tuple(map(int, config['target_size'].split(',')))
    
    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from weatherdiff.utils import prepare_weather_data, WeatherSequenceDataset, Normalizer
    from torch.utils.data import DataLoader
    
    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)
    
    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(':')
    ds = ds.sel(time=slice(start, end))
    
    # è·å–å˜é‡æ•°æ®
    data = ds[config['variable']].values  # (Time, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")
    
    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(data, 
                                n_channels=3,
                                target_size=target_size)
    print(f"å¤„ç†å shape: {data.shape}")
    print(f"  å›¾åƒå°ºå¯¸: {target_size}")
    print(f"  æ½œå‘é‡å°ºå¯¸: ({target_size[0]//8}, {target_size[1]//8})")
    
    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config['normalization'])
    normalizer.load_stats(normalizer_data['stats'])
    data = normalizer.transform(data, name=config['variable'])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    
    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, 
        config['input_length'], 
        config['output_length']
    )
    
    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # ========================================================================
    # Step 4: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: åŠ è½½æ¨¡å‹")
    print("-" * 80)
    
    model = WeatherDiffusion(
        input_length=config['input_length'],
        output_length=config['output_length'],
        latent_channels=4,
        base_channels=config['base_channels'],
        depth=config['depth']
    )
    
    checkpoint_path = model_dir / 'best_model.pt'
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(args.device)
    model.eval()
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = DDPMScheduler(
        num_train_timesteps=config['num_train_timesteps'],
        beta_schedule=config['beta_schedule']
    )
    
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========================================================================
    # Step 5: é‡‡æ ·é¢„æµ‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 5: æ‰©æ•£é‡‡æ ·é¢„æµ‹ï¼ˆä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç ï¼‰")
    print("-" * 80)
    
    vae_batch_size = args.vae_batch_size
    print(f"  VAE batch size: {vae_batch_size}")
    print(f"  é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"  æ¯ä¸ªè¾“å…¥ç”Ÿæˆæ ·æœ¬æ•°: {args.num_samples}")
    
    all_predictions = []
    all_targets = []
    all_inputs = []
    
    if args.num_samples > 1:
        all_ensemble = []  # å­˜å‚¨æ‰€æœ‰æ ·æœ¬ç”¨äºé›†æˆ
    
    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc='é¢„æµ‹ä¸­'):
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]
            
            # ç¼–ç è¾“å…¥åˆ°æ½œç©ºé—´
            inputs_flat = inputs.reshape(B * T_in, C, H, W)
            condition = encode_in_batches(vae_wrapper, inputs_flat, vae_batch_size, args.device)
            condition = condition.reshape(B, T_in, 4, H // 8, W // 8)
            
            # ç”Ÿæˆå¤šä¸ªæ ·æœ¬
            samples_list = []
            for sample_idx in range(args.num_samples):
                # æ‰©æ•£é‡‡æ ·
                latent_shape = (B, T_out, 4, H // 8, W // 8)
                latent_outputs = ddpm_sample(
                    model, condition, latent_shape, scheduler, 
                    args.device, args.num_inference_steps
                )
                
                # è§£ç å›åƒç´ ç©ºé—´
                latent_outputs_flat = latent_outputs.reshape(B * T_out, 4, H // 8, W // 8)
                outputs = decode_in_batches(vae_wrapper, latent_outputs_flat.cpu(), vae_batch_size, args.device)
                outputs = outputs.reshape(B, T_out, C, H, W)
                
                samples_list.append(outputs.cpu().numpy())
            
            # é›†æˆé¢„æµ‹ï¼ˆå¹³å‡ï¼‰
            samples = np.stack(samples_list, axis=0)  # (num_samples, B, T_out, C, H, W)
            ensemble_pred = samples.mean(axis=0)  # (B, T_out, C, H, W)
            
            all_predictions.append(ensemble_pred)
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())
            
            if args.num_samples > 1:
                all_ensemble.append(samples)
    
    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)
    
    if args.num_samples > 1:
        ensemble = np.concatenate(all_ensemble, axis=1)  # (num_samples, N, T_out, C, H, W)
    
    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")
    if args.num_samples > 1:
        print(f"  é›†æˆæ ·æœ¬å½¢çŠ¶: {ensemble.shape}")
    
    # ========================================================================
    # Step 6: åå½’ä¸€åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 6: è¯„ä¼°å’Œåå½’ä¸€åŒ–")
    print("-" * 80)
    
    # å½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡
    print("\nå½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡:")
    metrics_norm = calculate_metrics(y_pred, y_true, ensemble=False)
    print(format_metrics(metrics_norm))
    
    # åå½’ä¸€åŒ–åˆ°ç‰©ç†å•ä½
    variable = config['variable']
    C = y_pred.shape[2]
    H = y_pred.shape[3]
    W = y_pred.shape[4]
    
    y_pred_flat = y_pred.reshape(-1, C, H, W)
    y_true_flat = y_true.reshape(-1, C, H, W)
    
    y_pred_phys = normalizer.inverse_transform(y_pred_flat, name=variable)
    y_true_phys = normalizer.inverse_transform(y_true_flat, name=variable)
    
    y_pred_phys = y_pred_phys.reshape(y_pred.shape)
    y_true_phys = y_true_phys.reshape(y_true.shape)
    
    print("\nâœ“ åå½’ä¸€åŒ–å®Œæˆ")
    print(f"  é¢„æµ‹èŒƒå›´: [{y_pred_phys.min():.2f}, {y_pred_phys.max():.2f}] K")
    print(f"  çœŸå€¼èŒƒå›´: [{y_true_phys.min():.2f}, {y_true_phys.max():.2f}] K")
    
    # ç‰©ç†ç©ºé—´çš„æŒ‡æ ‡
    print("\nç‰©ç†ç©ºé—´çš„æŒ‡æ ‡ (åŸå§‹å°ºåº¦):")
    metrics_phys = calculate_metrics(y_pred_phys, y_true_phys, ensemble=False)
    print(format_metrics(metrics_phys))
    
    # è®¡ç®—æ¯ä¸ªlead timeçš„RMSE
    print("\næ¯ä¸ªlead timeçš„RMSE:")
    T_out = y_pred_phys.shape[1]
    rmse_per_leadtime = {}
    for t in range(T_out):
        y_pred_t = y_pred_phys[:, t, :, :, :]  # (N, C, H, W)
        y_true_t = y_true_phys[:, t, :, :, :]
        rmse_t = np.sqrt(np.mean((y_pred_t - y_true_t) ** 2))
        rmse_per_leadtime[f'rmse_step_{t+1}'] = float(rmse_t)
        print(f"  Step {t+1} ({(t+1)*6}h): {rmse_t:.4f} K")
    
    # ========================================================================
    # Step 7: ä¿å­˜ç»“æœ
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 7: ä¿å­˜ç»“æœ")
    print("-" * 80)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_all = {
        'mode': 'diffusion',
        'sampling_method': args.sampling_method,
        'num_samples': args.num_samples,
        'normalized_space': {k: float(v) for k, v in metrics_norm.items()},
        'physical_space': {k: float(v) for k, v in metrics_phys.items()},
        'physical_space_rmse_per_leadtime': rmse_per_leadtime,
        'time_slice': args.time_slice,
        'n_samples': int(y_pred.shape[0])
    }
    
    metrics_path = output_dir / 'prediction_metrics.json'
    with open(metrics_path, 'w') as f:
        json.dump(metrics_all, f, indent=2)
    print(f"âœ“ æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")
    
    # ä¿å­˜é¢„æµ‹æ•°æ®
    pred_dir = output_dir / "predictions_data"
    pred_dir.mkdir(exist_ok=True)
    np.save(pred_dir / 'y_test_pred_norm.npy', y_pred)
    np.save(pred_dir / 'y_test_norm.npy', y_true)
    np.save(pred_dir / 'y_test.npy', y_true_phys)
    np.save(pred_dir / 'y_test_pred.npy', y_pred_phys)
    
    if args.num_samples > 1:
        np.save(pred_dir / 'ensemble_samples.npy', ensemble)
        print(f"âœ“ é›†æˆæ ·æœ¬å·²ä¿å­˜: {pred_dir}/ensemble_samples.npy")
    
    print(f"âœ“ é¢„æµ‹æ•°æ®å·²ä¿å­˜: {pred_dir}/y_*.npy")
    
    # ========================================================================
    # Step 8: ç”Ÿæˆå¯è§†åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 8: ç”Ÿæˆå¯è§†åŒ–")
    print("-" * 80)
    
    # è·å–ç©ºé—´åæ ‡
    import xarray as xr
    ds = xr.open_zarr(args.data_path)
    
    spatial_coords = None
    if hasattr(ds, 'latitude') and hasattr(ds, 'longitude'):
        lat_values = ds.latitude.values
        lon_values = ds.longitude.values
        
        # è·å–é¢„æµ‹æ•°æ®çš„å®é™…ç©ºé—´å½¢çŠ¶
        # y_pred_phys shape: (N, T, C, H, W)
        actual_H = y_pred_phys.shape[3]
        actual_W = y_pred_phys.shape[4]
        
        print(f"\næ£€æŸ¥ç©ºé—´åæ ‡:")
        print(f"  æ•°æ®é›†åæ ‡: lat={len(lat_values)}, lon={len(lon_values)}")
        print(f"  é¢„æµ‹æ•°æ®å½¢çŠ¶: H={actual_H}, W={actual_W}")
        
        # æ£€æŸ¥åæ ‡ä¸æ•°æ®å½¢çŠ¶çš„å¯¹åº”å…³ç³»
        # ERA5 64x32æ•°æ®é›†çš„ç»´åº¦é¡ºåºæ˜¯ (time, longitude, latitude)
        # æ‰€ä»¥ H å¯¹åº” longitude (64), W å¯¹åº” latitude (32)
        if len(lon_values) == actual_H and len(lat_values) == actual_W:
            # ERA5æ ¼å¼: H=64(longitude), W=32(latitude)
            # visualization.pyæœŸæœ›: H=latitude, W=longitude
            # è§£å†³æ–¹æ¡ˆï¼šè½¬ç½®æ•°æ®çš„ç©ºé—´ç»´åº¦
            print(f"  âœ“ åæ ‡åŒ¹é… (ERA5æ ¼å¼: H={actual_H}(lon), W={actual_W}(lat))")
            print(f"  è½¬ç½®ç©ºé—´ç»´åº¦ä»¥é€‚é…visualization (Hâ†â†’W)")
            
            # è½¬ç½®ç©ºé—´ç»´åº¦: (N, T, C, H, W) â†’ (N, T, C, W, H)
            y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
            y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))
            
            # ç°åœ¨ H=32(latitude), W=64(longitude)ï¼Œç¬¦åˆvisualizationæœŸæœ›
            spatial_coords = {
                'lat': lat_values,  # 32ä¸ªçº¬åº¦å€¼
                'lon': lon_values,  # 64ä¸ªç»åº¦å€¼
            }
            print(f"  è½¬ç½®å: H={y_pred_phys.shape[3]}(lat), W={y_pred_phys.shape[4]}(lon)")
        elif len(lat_values) == actual_H and len(lon_values) == actual_W:
            # æ ‡å‡†æ ¼å¼: H=latitude, W=longitudeï¼ˆå·²ç»æ­£ç¡®ï¼‰
            spatial_coords = {
                'lat': lat_values,
                'lon': lon_values,
            }
            print(f"  âœ“ åæ ‡åŒ¹é… (æ ‡å‡†æ ¼å¼: H={actual_H}(lat), W={actual_W}(lon))")
        else:
            # å°ºå¯¸å®Œå…¨ä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤åæ ‡
            print(f"  âš  åæ ‡ç»´åº¦ä¸åŒ¹é… (lat:{len(lat_values)}, lon:{len(lon_values)} vs H:{actual_H}, W:{actual_W})")
            print(f"  ä½¿ç”¨é»˜è®¤åæ ‡...")
            spatial_coords = {
                'lat': np.linspace(-90, 90, actual_H),
                'lon': np.linspace(0, 360, actual_W),
            }
    
    # ç”Ÿæˆå¯è§†åŒ–
    # æ³¨æ„ï¼šWeatherDiffä½¿ç”¨minmaxå½’ä¸€åŒ–ï¼ˆ[-1,1]ï¼‰ï¼Œä¸ä¼ ç»Ÿæ¨¡å‹çš„zscoreä¸åŒ
    # è¿™é‡Œä¼ é€’å·²ç»åå½’ä¸€åŒ–çš„ç‰©ç†å€¼æ•°æ®ï¼Œnorm_params=None
    # å¯è§†åŒ–å‡½æ•°ä¼šç”Ÿæˆtimeseries_overallï¼ˆç‰©ç†å€¼ï¼‰ï¼Œä½†ä¸ä¼šç”Ÿæˆtimeseries_physical
    # ï¼ˆå› ä¸ºWeatherDiffçš„å½’ä¸€åŒ–æ–¹å¼ä¸å¯è§†åŒ–å‡½æ•°é¢„æœŸä¸å…¼å®¹ï¼‰
    visualize_predictions_improved(
        y_true_phys,           # y_test (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        y_pred_phys,           # y_test_pred (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        metrics_phys,          # test_metrics (ç‰©ç†ç©ºé—´æŒ‡æ ‡)
        [variable],            # variables
        'diffusion',           # model_name
        output_dir,            # output_dir
        'spatial',             # data_format
        norm_params=None,      # norm_params (ä¸æä¾›ï¼Œå› ä¸ºå½’ä¸€åŒ–æ–¹å¼ä¸åŒ)
        spatial_coords=spatial_coords  # spatial_coords
    )
    
    print(f"âœ“ å¯è§†åŒ–å·²ç”Ÿæˆ")
    print(f"  - timeseries_overall_{variable}.png (ç‰©ç†å€¼)")
    print(f"  - timeseries_physical_{variable}.png (æœªç”Ÿæˆï¼Œå› ä¸ºå·²ä½¿ç”¨ç‰©ç†å€¼ç»˜åˆ¶overall)")
    print(f"  - leadtime_independent_{variable}.png")
    print(f"  - rmse_vs_leadtime_{variable}.png")
    print(f"  - spatial_comparison_{variable}.png")
    
    # ========================================================================
    # æ€»ç»“
    # ========================================================================
    print("\n" + "=" * 80)
    print("é¢„æµ‹å®Œæˆ!")
    print("=" * 80)
    
    print(f"\næ¨¡å‹: DIFFUSION ({args.sampling_method.upper()})")
    print(f"æ€»ç»“ (ç‰©ç†ç©ºé—´):")
    print(f"  æ ·æœ¬æ•°: {y_pred.shape[0]}")
    print(f"  RMSE: {metrics_phys['rmse']:.4f} K")
    print(f"  MAE: {metrics_phys['mae']:.4f} K")
    print(f"  ç›¸å…³ç³»æ•°: {metrics_phys['correlation']:.4f}")
    print(f"  SSIM: {metrics_phys['ssim']:.4f}")
    
    if args.num_samples > 1:
        print(f"\né›†æˆé¢„æµ‹:")
        print(f"  æ ·æœ¬æ•°: {args.num_samples}")
        print(f"  ä¸ç¡®å®šæ€§æ•°æ®å·²ä¿å­˜")
    
    print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"  - prediction_metrics.json: è¯¦ç»†æŒ‡æ ‡")
    print(f"  - y_pred_*.npy: é¢„æµ‹æ•°æ®")
    print(f"  - *.png: å¯è§†åŒ–å›¾ç‰‡")


if __name__ == '__main__':
    main()

