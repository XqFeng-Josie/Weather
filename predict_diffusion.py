"""
æ‰©æ•£æ¨¡å‹é¢„æµ‹è„šæœ¬ - æ¦‚ç‡å¼å¤©æ°”é¢„æµ‹

ğŸ“‹ æ–‡ä»¶ä½œç”¨:
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¦‚ç‡å¼é¢„æµ‹ï¼Œé€šè¿‡é‡‡æ ·ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„æœªæ¥çŠ¶æ€ã€‚
    
ğŸ”„ é¢„æµ‹æµç¨‹:
    1. åŠ è½½è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹å’Œé…ç½®
    2. åŠ è½½VAEæ¨¡å‹
    3. åŠ è½½æµ‹è¯•æ•°æ®
    4. VAEåˆ†æ‰¹ç¼–ç è¾“å…¥åºåˆ—åˆ°æ½œç©ºé—´
    5. ä»çº¯å™ªå£°å¼€å§‹ï¼Œé€æ­¥å»å™ªç”Ÿæˆé¢„æµ‹ï¼ˆDDPM/DDIMé‡‡æ ·ï¼‰
    6. VAEåˆ†æ‰¹è§£ç å›åƒç´ ç©ºé—´
    7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå•æ¬¡é¢„æµ‹ + é›†æˆé¢„æµ‹ï¼‰
    8. ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ—¶é—´åºåˆ—å›¾ + ä¸–ç•Œåœ°å›¾å¯¹æ¯” + ä¸ç¡®å®šæ€§å›¾ï¼‰
    9. ä¿å­˜æ‰€æœ‰ç»“æœ
    
âš¡ æ˜¾å­˜ä¼˜åŒ–:
    - VAEåˆ†æ‰¹ç¼–ç /è§£ç ï¼ˆä¸train_diffusion.pyä¸€è‡´ï¼‰
    - æ”¯æŒå¤šæ¬¡é‡‡æ ·ç”Ÿæˆé›†æˆé¢„æµ‹
    - é»˜è®¤vae_batch_size=4ï¼Œé€‚åˆ12GB GPU
    
ğŸ“Š è¾“å‡ºæ–‡ä»¶:
    - prediction_metrics.json: è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
    - y_pred_*.npy: é¢„æµ‹æ•°æ®
    - y_true_*.npy: çœŸå€¼æ•°æ®
    - ensemble_*.npy: é›†æˆé¢„æµ‹æ•°æ®ï¼ˆå¦‚æœnum_samples>1ï¼‰
    - timeseries_*.png: æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
    - spatial_comparison_*.png: ä¸–ç•Œåœ°å›¾å¯¹æ¯”å›¾
    - uncertainty_*.png: é¢„æµ‹ä¸ç¡®å®šæ€§å›¾ï¼ˆé›†æˆé¢„æµ‹ï¼‰
    
ğŸ“– ä½¿ç”¨æ–¹æ³•:
    # å•æ¬¡é¢„æµ‹
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --time-slice 2020-01-01:2020-12-31 \\
        --vae-batch-size 4
    
    # é›†æˆé¢„æµ‹ï¼ˆç”Ÿæˆå¤šä¸ªæ ·æœ¬ï¼‰
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --time-slice 2020-01-01:2020-12-31 \\
        --num-samples 10 \\
        --vae-batch-size 4
    
    # ä½¿ç”¨DDIMé‡‡æ ·ï¼ˆæ›´å¿«ï¼‰
    python predict_diffusion.py \\
        --model-dir outputs/diffusion \\
        --sampling-method ddim \\
        --num-inference-steps 50

ğŸ¯ é¢„æœŸæ•ˆæœ:
    å•æ¬¡é¢„æµ‹:
        - RMSE: 3-6K
        - ç›¸å…³ç³»æ•°: > 0.98
        - SSIM: > 0.98
    
    é›†æˆé¢„æµ‹:
        - RMSE: 2-4K (é›†æˆåæ›´å‡†ç¡®)
        - æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡
"""

import argparse
import torch
import numpy as np
import json
import pickle
from pathlib import Path
from tqdm import tqdm

from weatherdiff.diffusion import WeatherDiffusion, DDPMScheduler
from weatherdiff.vae import SDVAEWrapper
from weatherdiff.utils import WeatherDataModule, calculate_metrics, format_metrics
from src.visualization import visualize_predictions_improved


def encode_in_batches(vae_wrapper, images, vae_batch_size=4, device="cuda"):
    """
    åˆ†æ‰¹ç¼–ç å›¾åƒåˆ°æ½œç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰

    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        images: (N, C, H, W) å›¾åƒtensor
        vae_batch_size: VAEç¼–ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡

    Returns:
        latents: (N, 4, H//8, W//8) æ½œå‘é‡
    """
    N = images.shape[0]
    latent_list = []

    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = images[i:end_idx].to(device)
        latent_batch = vae_wrapper.encode(batch)
        latent_list.append(latent_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜

        # æ¸…ç†æ˜¾å­˜
        del batch, latent_batch
        torch.cuda.empty_cache()

    # åˆå¹¶æ‰€æœ‰batch
    latents = torch.cat(latent_list, dim=0).to(device)
    return latents


def decode_in_batches(vae_wrapper, latents, vae_batch_size=4, device="cuda"):
    """
    åˆ†æ‰¹è§£ç æ½œå‘é‡åˆ°åƒç´ ç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰

    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        latents: (N, 4, H//8, W//8) æ½œå‘é‡tensor
        vae_batch_size: VAEè§£ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡

    Returns:
        images: (N, 3, H, W) å›¾åƒ
    """
    N = latents.shape[0]
    image_list = []

    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = latents[i:end_idx].to(device)
        image_batch = vae_wrapper.decode(batch)
        image_list.append(image_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜

        # æ¸…ç†æ˜¾å­˜
        del batch, image_batch
        torch.cuda.empty_cache()

    # åˆå¹¶æ‰€æœ‰batch
    images = torch.cat(image_list, dim=0).to(device)
    return images


def ddpm_sample(
    model, condition, latent_shape, scheduler, device, num_inference_steps=None
):
    """
    DDPMé‡‡æ ·ï¼ˆé€æ­¥å»å™ªï¼‰

    Args:
        model: æ‰©æ•£æ¨¡å‹
        condition: æ¡ä»¶ï¼ˆè¾“å…¥åºåˆ—çš„æ½œå‘é‡ï¼‰
        latent_shape: æ½œå‘é‡å½¢çŠ¶ (B, T_out, 4, H//8, W//8)
        scheduler: DDPMè°ƒåº¦å™¨
        device: è®¾å¤‡
        num_inference_steps: æ¨ç†æ­¥æ•°ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ­¥æ•°ï¼‰

    Returns:
        samples: é‡‡æ ·ç»“æœ (B, T_out, 4, H//8, W//8)
    """
    # ä»çº¯å™ªå£°å¼€å§‹
    latent = torch.randn(latent_shape, device=device)

    # è®¾ç½®æ¨ç†æ­¥æ•°
    if num_inference_steps is None:
        num_inference_steps = scheduler.num_train_timesteps

    timesteps = torch.linspace(
        scheduler.num_train_timesteps - 1,
        0,
        num_inference_steps,
        dtype=torch.long,
        device=device,
    )

    # é€æ­¥å»å™ª
    for t in tqdm(timesteps, desc="DDPMé‡‡æ ·"):
        with torch.no_grad():
            # é¢„æµ‹å™ªå£°
            noise_pred = model(
                latent, t.unsqueeze(0).expand(latent_shape[0]), condition
            )

            # å»å™ªä¸€æ­¥
            latent = scheduler.step(noise_pred, t, latent)

    return latent


def main():
    parser = argparse.ArgumentParser(description="æ‰©æ•£æ¨¡å‹é¢„æµ‹")

    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        "--model-dir",
        type=str,
        default="outputs/diffusion",
        help="æ¨¡å‹ç›®å½•ï¼ˆåŒ…å«best_model.ptå’Œconfig.jsonï¼‰",
    )

    # æ•°æ®å‚æ•°
    parser.add_argument(
        "--data-path",
        type=str,
        default="gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr",
        help="æ•°æ®è·¯å¾„",
    )
    parser.add_argument(
        "--time-slice", type=str, default="2020-01-01:2020-12-31", help="é¢„æµ‹æ—¶é—´èŒƒå›´"
    )

    # é‡‡æ ·å‚æ•°
    parser.add_argument(
        "--sampling-method",
        type=str,
        default="ddpm",
        choices=["ddpm", "ddim"],
        help="é‡‡æ ·æ–¹æ³•",
    )
    parser.add_argument(
        "--num-inference-steps",
        type=int,
        default=None,
        help="æ¨ç†æ­¥æ•°ï¼ˆNone=ä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ­¥æ•°ï¼‰",
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=1,
        help="æ¯ä¸ªè¾“å…¥ç”Ÿæˆçš„æ ·æœ¬æ•°ï¼ˆç”¨äºé›†æˆé¢„æµ‹ï¼‰",
    )

    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--output-dir", type=str, default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹ç›®å½•ï¼‰"
    )
    parser.add_argument("--batch-size", type=int, default=16, help="é¢„æµ‹æ‰¹æ¬¡å¤§å°")
    parser.add_argument(
        "--vae-batch-size",
        type=int,
        default=4,
        help="VAEç¼–ç /è§£ç æ‰¹æ¬¡å¤§å°ï¼ˆæ§åˆ¶æ˜¾å­˜å ç”¨ï¼‰",
    )
    parser.add_argument(
        "--levels",
        type=int,
        nargs="+",
        default=None,
        help="é€‰æ‹©ç‰¹å®šçš„æ°”å‹å±‚è¿›è¡Œè¯„ä¼°/å¯è§†åŒ– (e.g. --levels 500 or --levels 500 700 850). "
        "Levelså¿…é¡»ä¸è®­ç»ƒæ—¶é…ç½®ä¸­çš„levelsä¸€è‡´ã€‚å¦‚æœä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨æ‰€æœ‰levelsã€‚",
    )

    # å…¶ä»–å‚æ•°
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="è®¾å¤‡",
    )

    args = parser.parse_args()

    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "=" * 80)
    print("æ‰©æ•£æ¨¡å‹é¢„æµ‹ - æ¦‚ç‡å¼å¤©æ°”é¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"æ ·æœ¬æ•°: {args.num_samples}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)

    config_path = model_dir / "config.json"
    with open(config_path, "r") as f:
        config = json.load(f)

    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")
    print(f"  VAEæ¨¡å‹: {config['vae_model_id']}")

    # ä»configè¯»å–è®­ç»ƒæ—¶ä½¿ç”¨çš„ levelsï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    available_levels = config.get("levels", None)
    if available_levels is not None:
        print(f"  è®­ç»ƒæ—¶ä½¿ç”¨çš„levels: {available_levels}")
    else:
        print(f"  è®­ç»ƒæ—¶ä½¿ç”¨çš„levels: æ‰€æœ‰å¯ç”¨çš„levelsï¼ˆé»˜è®¤ï¼‰")

    # å¤„ç†å‘½ä»¤è¡ŒæŒ‡å®šçš„ --levels å‚æ•°
    selected_levels = args.levels
    channel_indices = None  # ç”¨äºåç»­é€‰æ‹©æŒ‡å®šçš„ channels
    if selected_levels is not None:
        if available_levels is None:
            raise ValueError(
                "No 'levels' found in config. Cannot select specific levels. "
                "Please use all levels (omit --levels argument)."
            )

        # ç¡®ä¿ available_levels æ˜¯åˆ—è¡¨
        if not isinstance(available_levels, list):
            available_levels = [available_levels]

        # æ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„ levels æ˜¯å¦åœ¨å¯ç”¨çš„ levels ä¸­
        invalid_levels = [l for l in selected_levels if l not in available_levels]
        if invalid_levels:
            raise ValueError(
                f"Invalid levels: {invalid_levels}. "
                f"Available levels from config: {available_levels}"
            )

        # å°† level å€¼è½¬æ¢ä¸º channel ç´¢å¼•
        # channel çš„é¡ºåºä¸ available_levels çš„é¡ºåºä¸€è‡´
        channel_indices = []
        for level in selected_levels:
            if level in available_levels:
                channel_indices.append(available_levels.index(level))

        print(
            f"  é€‰æ‹©levels {selected_levels} è¿›è¡Œè¯„ä¼°/å¯è§†åŒ– "
            f"(channel indices: {channel_indices})"
        )
    else:
        print(f"  ä½¿ç”¨æ‰€æœ‰levelsè¿›è¡Œè¯„ä¼°/å¯è§†åŒ–")

    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / "normalizer_stats.pkl"
    with open(normalizer_path, "rb") as f:
        normalizer_data = pickle.load(f)

    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")

    # ========================================================================
    # Step 2: åŠ è½½VAE
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½VAE")
    print("-" * 80)

    vae_wrapper = SDVAEWrapper(model_id=config["vae_model_id"], device=args.device)
    print(f"âœ“ VAEåŠ è½½å®Œæˆ")

    # ========================================================================
    # Step 3: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ•°æ®")
    print("-" * 80)

    target_size = tuple(map(int, config["target_size"].split(",")))

    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from weatherdiff.utils import (
        prepare_weather_data,
        WeatherSequenceDataset,
        Normalizer,
    )
    from torch.utils.data import DataLoader

    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)

    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(":")
    ds = ds.sel(time=slice(start, end))

    # è·å–å˜é‡æ•°æ®
    variable_da = ds[config["variable"]]

    # å¦‚æœæœ‰levelç»´åº¦ï¼Œæ ¹æ®configä¸­çš„levelsè¿›è¡Œé€‰æ‹©ï¼ˆç”¨äºæ•°æ®åŠ è½½ï¼‰
    # æ³¨æ„ï¼šæ•°æ®åŠ è½½æ—¶éœ€è¦ä½¿ç”¨è®­ç»ƒæ—¶ä½¿ç”¨çš„æ‰€æœ‰levelsï¼Œè€Œä¸æ˜¯å‘½ä»¤è¡ŒæŒ‡å®šçš„selected_levels
    # selected_levelsåªç”¨äºåç»­çš„è¯„ä¼°å’Œå¯è§†åŒ–
    if "level" in variable_da.dims:
        if available_levels is not None:
            # ä½¿ç”¨è®­ç»ƒæ—¶æŒ‡å®šçš„ levelsï¼ˆæ‰€æœ‰levelsï¼‰
            print(f"  å˜é‡æœ‰levelç»´åº¦ï¼Œä½¿ç”¨è®­ç»ƒæ—¶çš„levels: {available_levels}")
            variable_da = variable_da.sel(level=available_levels)
            # ç¡®ä¿é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
            actual_levels = variable_da.level.values.tolist()
            print(f"  å®é™…åŠ è½½çš„levels: {actual_levels}")
        else:
            # ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ levels
            available_levels_from_data = variable_da.level.values.tolist()
            print(
                f"  å˜é‡æœ‰levelç»´åº¦ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„levels: {available_levels_from_data}"
            )
            available_levels = available_levels_from_data
            actual_levels = available_levels_from_data

    data = variable_da.values  # (Time, H, W) æˆ– (Time, Level, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")

    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(data, n_channels=3, target_size=target_size)
    print(f"å¤„ç†å shape: {data.shape}")
    print(f"  å›¾åƒå°ºå¯¸: {target_size}")
    print(f"  æ½œå‘é‡å°ºå¯¸: ({target_size[0]//8}, {target_size[1]//8})")

    # éªŒè¯æ•°æ®å°ºå¯¸æ˜¯å¦ä¸target_sizeä¸€è‡´
    _, _, data_H, data_W = data.shape
    if data_H != target_size[0] or data_W != target_size[1]:
        raise ValueError(
            f"æ•°æ®å°ºå¯¸ä¸åŒ¹é…ï¼š\n"
            f"  æ•°æ®åŠ è½½åçš„å°ºå¯¸: ({data_H}, {data_W})\n"
            f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
            f"  å¯èƒ½åŸå› ï¼šprepare_weather_dataæœªæ­£ç¡®resizeåˆ°target_size\n"
            f"  è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥prepare_weather_dataçš„target_sizeå‚æ•°æ˜¯å¦æ­£ç¡®ä¼ é€’"
        )

    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config["normalization"])

    # åŠ è½½å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼ˆæ”¯æŒæŒ‰levelå½’ä¸€åŒ–ï¼‰
    if (
        "normalize_per_level" in normalizer_data
        and normalizer_data["normalize_per_level"]
    ):
        # æŒ‰levelå½’ä¸€åŒ–ï¼šä¼ é€’å®Œæ•´çš„normalizer_data
        normalizer.load_stats(normalizer_data)
        # ä»configæˆ–metadataä¸­è·å–n_channels_per_level
        if "n_channels" in config:
            normalizer.n_channels_per_level = config["n_channels"]
        else:
            # å°è¯•ä»æ•°æ®å½¢çŠ¶æ¨æ–­
            _, C, _, _ = data.shape
            if "levels" in normalizer_data and normalizer_data["levels"]:
                n_levels = len(normalizer_data["levels"])
                if C % n_levels == 0:
                    normalizer.n_channels_per_level = C // n_levels
                    print(f"  æ¨æ–­æ¯ä¸ªlevelçš„é€šé“æ•°: {normalizer.n_channels_per_level}")
                else:
                    raise ValueError(
                        f"æ— æ³•æ¨æ–­æ¯ä¸ªlevelçš„é€šé“æ•°ã€‚æ€»é€šé“æ•°: {C}, Levelsæ•°: {n_levels}"
                    )
    else:
        # å…¨å±€å½’ä¸€åŒ–ï¼šåªä¼ é€’stats
        normalizer.load_stats(normalizer_data.get("stats", normalizer_data))

    data = normalizer.transform(data, name=config["variable"])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")

    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, config["input_length"], config["output_length"]
    )

    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True,
    )

    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")

    # ========================================================================
    # Step 4: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: åŠ è½½æ¨¡å‹")
    print("-" * 80)

    model = WeatherDiffusion(
        input_length=config["input_length"],
        output_length=config["output_length"],
        latent_channels=4,
        base_channels=config["base_channels"],
        depth=config["depth"],
    )

    checkpoint_path = model_dir / "best_model.pt"
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(args.device)
    model.eval()

    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = DDPMScheduler(
        num_train_timesteps=config["num_train_timesteps"],
        beta_schedule=config["beta_schedule"],
    )

    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ========================================================================
    # Step 5: é‡‡æ ·é¢„æµ‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 5: æ‰©æ•£é‡‡æ ·é¢„æµ‹ï¼ˆä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç ï¼‰")
    print("-" * 80)

    vae_batch_size = args.vae_batch_size
    print(f"  VAE batch size: {vae_batch_size}")
    print(f"  é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"  æ¯ä¸ªè¾“å…¥ç”Ÿæˆæ ·æœ¬æ•°: {args.num_samples}")

    all_predictions = []
    all_targets = []
    all_inputs = []

    if args.num_samples > 1:
        all_ensemble = []  # å­˜å‚¨æ‰€æœ‰æ ·æœ¬ç”¨äºé›†æˆ

    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc="é¢„æµ‹ä¸­"):
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]

            # ç¼–ç è¾“å…¥åˆ°æ½œç©ºé—´
            inputs_flat = inputs.reshape(B * T_in, C, H, W)
            condition = encode_in_batches(
                vae_wrapper, inputs_flat, vae_batch_size, args.device
            )
            condition = condition.reshape(B, T_in, 4, H // 8, W // 8)

            # ç”Ÿæˆå¤šä¸ªæ ·æœ¬
            samples_list = []
            for sample_idx in range(args.num_samples):
                # æ‰©æ•£é‡‡æ ·
                latent_shape = (B, T_out, 4, H // 8, W // 8)
                latent_outputs = ddpm_sample(
                    model,
                    condition,
                    latent_shape,
                    scheduler,
                    args.device,
                    args.num_inference_steps,
                )

                # è§£ç å›åƒç´ ç©ºé—´
                latent_outputs_flat = latent_outputs.reshape(
                    B * T_out, 4, H // 8, W // 8
                )
                outputs = decode_in_batches(
                    vae_wrapper, latent_outputs_flat.cpu(), vae_batch_size, args.device
                )

                # éªŒè¯è§£ç åçš„å°ºå¯¸
                _, _, decoded_H, decoded_W = outputs.shape
                outputs = outputs.reshape(B, T_out, C, decoded_H, decoded_W)

                # ä¸¥æ ¼éªŒè¯ï¼šè§£ç åçš„å°ºå¯¸å¿…é¡»ç­‰äºtarget_sizeï¼ˆè®­ç»ƒæ—¶çš„å°ºå¯¸ï¼‰
                if decoded_H != target_size[0] or decoded_W != target_size[1]:
                    raise ValueError(
                        f"ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š\n"
                        f"  VAEè§£ç è¾“å‡ºå°ºå¯¸: ({decoded_H}, {decoded_W})\n"
                        f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
                        f"  é¢„æµ‹æ—¶è¾“å…¥å°ºå¯¸: ({H}, {W})\n"
                        f"  å¯èƒ½åŸå› ï¼š\n"
                        f"    1. é¢„æµ‹æ—¶æ•°æ®åŠ è½½æœªä½¿ç”¨æ­£ç¡®çš„target_size\n"
                        f"    2. VAEé…ç½®ä¸è®­ç»ƒæ—¶ä¸ä¸€è‡´\n"
                        f"    3. æ•°æ®åŠ è½½åæœªæ­£ç¡®resizeåˆ°target_size\n"
                        f"  è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿é¢„æµ‹æ—¶ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„target_sizeå’ŒVAEé…ç½®"
                    )

                # éªŒè¯è¾“å…¥å°ºå¯¸ä¹Ÿç­‰äºtarget_size
                if H != target_size[0] or W != target_size[1]:
                    raise ValueError(
                        f"ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š\n"
                        f"  é¢„æµ‹æ—¶è¾“å…¥å°ºå¯¸: ({H}, {W})\n"
                        f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
                        f"  å¯èƒ½åŸå› ï¼šæ•°æ®åŠ è½½æ—¶æœªæ­£ç¡®resizeåˆ°target_size\n"
                        f"  è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥prepare_weather_dataæ˜¯å¦æ­£ç¡®ä½¿ç”¨target_sizeå‚æ•°"
                    )

                samples_list.append(outputs.cpu().numpy())

            # é›†æˆé¢„æµ‹ï¼ˆå¹³å‡ï¼‰
            samples = np.stack(samples_list, axis=0)  # (num_samples, B, T_out, C, H, W)
            ensemble_pred = samples.mean(axis=0)  # (B, T_out, C, H, W)

            all_predictions.append(ensemble_pred)
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())

            if args.num_samples > 1:
                all_ensemble.append(samples)

    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)

    if args.num_samples > 1:
        ensemble = np.concatenate(
            all_ensemble, axis=1
        )  # (num_samples, N, T_out, C, H, W)

    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")
    if args.num_samples > 1:
        print(f"  é›†æˆæ ·æœ¬å½¢çŠ¶: {ensemble.shape}")

    # ========================================================================
    # Step 6: åå½’ä¸€åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 6: è¯„ä¼°å’Œåå½’ä¸€åŒ–")
    print("-" * 80)

    # å¦‚æœæŒ‡å®šäº† --levelsï¼Œåªé€‰æ‹©å¯¹åº”çš„ channels è¿›è¡Œè¯„ä¼°
    if channel_indices is not None:
        print(f"\né€‰æ‹© channels {channel_indices} (levels {selected_levels}) è¿›è¡Œè¯„ä¼°")
        y_pred_selected = y_pred[:, :, channel_indices, :, :]
        y_true_selected = y_true[:, :, channel_indices, :, :]
    else:
        y_pred_selected = y_pred
        y_true_selected = y_true

    # å½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡
    print("\nå½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡:")
    metrics_norm = calculate_metrics(y_pred_selected, y_true_selected, ensemble=False)
    print(format_metrics(metrics_norm))

    # åå½’ä¸€åŒ–åˆ°ç‰©ç†å•ä½
    variable = config["variable"]
    C = y_pred.shape[2]
    H = y_pred.shape[3]
    W = y_pred.shape[4]

    y_pred_flat = y_pred.reshape(-1, C, H, W)
    y_true_flat = y_true.reshape(-1, C, H, W)

    y_pred_phys = normalizer.inverse_transform(y_pred_flat, name=variable)
    y_true_phys = normalizer.inverse_transform(y_true_flat, name=variable)

    y_pred_phys = y_pred_phys.reshape(y_pred.shape)
    y_true_phys = y_true_phys.reshape(y_true.shape)

    print("\nâœ“ åå½’ä¸€åŒ–å®Œæˆ")
    print(f"  é¢„æµ‹èŒƒå›´: [{y_pred_phys.min():.2f}, {y_pred_phys.max():.2f}] K")
    print(f"  çœŸå€¼èŒƒå›´: [{y_true_phys.min():.2f}, {y_true_phys.max():.2f}] K")

    # å¦‚æœæŒ‡å®šäº† --levelsï¼Œåªé€‰æ‹©å¯¹åº”çš„ channels è¿›è¡Œè¯„ä¼°
    if channel_indices is not None:
        y_pred_phys_selected = y_pred_phys[:, :, channel_indices, :, :]
        y_true_phys_selected = y_true_phys[:, :, channel_indices, :, :]
    else:
        y_pred_phys_selected = y_pred_phys
        y_true_phys_selected = y_true_phys

    # ç‰©ç†ç©ºé—´çš„æŒ‡æ ‡
    print("\nç‰©ç†ç©ºé—´çš„æŒ‡æ ‡ (åŸå§‹å°ºåº¦):")
    metrics_phys = calculate_metrics(
        y_pred_phys_selected, y_true_phys_selected, ensemble=False
    )
    print(format_metrics(metrics_phys))

    # è®¡ç®—æ¯ä¸ªlead timeçš„RMSE
    print("\næ¯ä¸ªlead timeçš„RMSE:")
    T_out = y_pred_phys_selected.shape[1]
    rmse_per_leadtime = {}
    for t in range(T_out):
        y_pred_t = y_pred_phys_selected[:, t, :, :, :]  # (N, C, H, W)
        y_true_t = y_true_phys_selected[:, t, :, :, :]
        rmse_t = np.sqrt(np.mean((y_pred_t - y_true_t) ** 2))
        rmse_per_leadtime[f"rmse_step_{t+1}"] = float(rmse_t)
        print(f"  Step {t+1} ({(t+1)*6}h): {rmse_t:.4f} K")

    # ========================================================================
    # Step 7: ä¿å­˜ç»“æœ
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 7: ä¿å­˜ç»“æœ")
    print("-" * 80)

    # ä¿å­˜æŒ‡æ ‡
    metrics_all = {
        "mode": "diffusion",
        "sampling_method": args.sampling_method,
        "num_samples": args.num_samples,
        "normalized_space": {k: float(v) for k, v in metrics_norm.items()},
        "physical_space": {k: float(v) for k, v in metrics_phys.items()},
        "physical_space_rmse_per_leadtime": rmse_per_leadtime,
        "time_slice": args.time_slice,
        "n_samples": int(y_pred.shape[0]),
    }

    metrics_path = output_dir / "prediction_metrics.json"
    with open(metrics_path, "w") as f:
        json.dump(metrics_all, f, indent=2)
    print(f"âœ“ æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")

    # ä¿å­˜é¢„æµ‹æ•°æ®
    pred_dir = output_dir / "predictions_data"
    pred_dir.mkdir(exist_ok=True)
    np.save(pred_dir / "y_test_pred_norm.npy", y_pred)
    np.save(pred_dir / "y_test_norm.npy", y_true)
    np.save(pred_dir / "y_test.npy", y_true_phys)
    np.save(pred_dir / "y_test_pred.npy", y_pred_phys)

    if args.num_samples > 1:
        np.save(pred_dir / "ensemble_samples.npy", ensemble)
        print(f"âœ“ é›†æˆæ ·æœ¬å·²ä¿å­˜: {pred_dir}/ensemble_samples.npy")

    print(f"âœ“ é¢„æµ‹æ•°æ®å·²ä¿å­˜: {pred_dir}/y_*.npy")

    # ========================================================================
    # Step 8: ç”Ÿæˆå¯è§†åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 8: ç”Ÿæˆå¯è§†åŒ–")
    print("-" * 80)

    # è·å–ç©ºé—´åæ ‡
    import xarray as xr

    ds = xr.open_zarr(args.data_path)

    spatial_coords = None
    if hasattr(ds, "latitude") and hasattr(ds, "longitude"):
        lat_values = ds.latitude.values
        lon_values = ds.longitude.values

        # è·å–é¢„æµ‹æ•°æ®çš„å®é™…ç©ºé—´å½¢çŠ¶
        # y_pred_phys shape: (N, T, C, H, W)
        actual_H = y_pred_phys.shape[3]
        actual_W = y_pred_phys.shape[4]

        print(f"\næ£€æŸ¥ç©ºé—´åæ ‡:")
        print(f"  æ•°æ®é›†åæ ‡: lat={len(lat_values)}, lon={len(lon_values)}")
        print(f"  é¢„æµ‹æ•°æ®å½¢çŠ¶: H={actual_H}, W={actual_W}")

        # æ£€æŸ¥åæ ‡ä¸æ•°æ®å½¢çŠ¶çš„å¯¹åº”å…³ç³»
        # ERA5 64x32æ•°æ®é›†çš„ç»´åº¦é¡ºåºæ˜¯ (time, longitude, latitude)
        # æ‰€ä»¥ H å¯¹åº” longitude (64), W å¯¹åº” latitude (32)
        if len(lon_values) == actual_H and len(lat_values) == actual_W:
            # ERA5æ ¼å¼: H=64(longitude), W=32(latitude)
            # visualization.pyæœŸæœ›: H=latitude, W=longitude
            # è§£å†³æ–¹æ¡ˆï¼šè½¬ç½®æ•°æ®çš„ç©ºé—´ç»´åº¦
            print(f"  âœ“ åæ ‡åŒ¹é… (ERA5æ ¼å¼: H={actual_H}(lon), W={actual_W}(lat))")
            print(f"  è½¬ç½®ç©ºé—´ç»´åº¦ä»¥é€‚é…visualization (Hâ†â†’W)")

            # è½¬ç½®ç©ºé—´ç»´åº¦: (N, T, C, H, W) â†’ (N, T, C, W, H)
            y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
            y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))

            # ç°åœ¨ H=32(latitude), W=64(longitude)ï¼Œç¬¦åˆvisualizationæœŸæœ›
            spatial_coords = {
                "lat": lat_values,  # 32ä¸ªçº¬åº¦å€¼
                "lon": lon_values,  # 64ä¸ªç»åº¦å€¼
            }
            print(
                f"  è½¬ç½®å: H={y_pred_phys.shape[3]}(lat), W={y_pred_phys.shape[4]}(lon)"
            )
        elif len(lat_values) == actual_H and len(lon_values) == actual_W:
            # æ ‡å‡†æ ¼å¼: H=latitude, W=longitudeï¼ˆå·²ç»æ­£ç¡®ï¼‰
            spatial_coords = {
                "lat": lat_values,
                "lon": lon_values,
            }
            print(f"  âœ“ åæ ‡åŒ¹é… (æ ‡å‡†æ ¼å¼: H={actual_H}(lat), W={actual_W}(lon))")
        else:
            # å°ºå¯¸å®Œå…¨ä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤åæ ‡
            print(
                f"  âš  åæ ‡ç»´åº¦ä¸åŒ¹é… (lat:{len(lat_values)}, lon:{len(lon_values)} vs H:{actual_H}, W:{actual_W})"
            )
            print(f"  ä½¿ç”¨é»˜è®¤åæ ‡...")
            spatial_coords = {
                "lat": np.linspace(-90, 90, actual_H),
                "lon": np.linspace(0, 360, actual_W),
            }

    # ç”Ÿæˆå¯è§†åŒ–
    # æ³¨æ„ï¼šWeatherDiffä½¿ç”¨minmaxå½’ä¸€åŒ–ï¼ˆ[-1,1]ï¼‰ï¼Œä¸ä¼ ç»Ÿæ¨¡å‹çš„zscoreä¸åŒ
    # è¿™é‡Œä¼ é€’å·²ç»åå½’ä¸€åŒ–çš„ç‰©ç†å€¼æ•°æ®ï¼Œnorm_params=None
    # å¯è§†åŒ–å‡½æ•°ä¼šç”Ÿæˆtimeseries_overallï¼ˆç‰©ç†å€¼ï¼‰ï¼Œä½†ä¸ä¼šç”Ÿæˆtimeseries_physical
    # ï¼ˆå› ä¸ºWeatherDiffçš„å½’ä¸€åŒ–æ–¹å¼ä¸å¯è§†åŒ–å‡½æ•°é¢„æœŸä¸å…¼å®¹ï¼‰
    visualize_predictions_improved(
        y_true_phys_selected,  # y_test (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        y_pred_phys_selected,  # y_test_pred (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        metrics_phys,  # test_metrics (ç‰©ç†ç©ºé—´æŒ‡æ ‡)
        [variable],  # variables
        "diffusion",  # model_name
        output_dir,  # output_dir
        "spatial",  # data_format
        norm_params=None,  # norm_params (ä¸æä¾›ï¼Œå› ä¸ºå½’ä¸€åŒ–æ–¹å¼ä¸åŒ)
        spatial_coords=spatial_coords,  # spatial_coords
    )

    print(f"âœ“ å¯è§†åŒ–å·²ç”Ÿæˆ")
    print(f"  - timeseries_overall_{variable}.png (ç‰©ç†å€¼)")
    print(
        f"  - timeseries_physical_{variable}.png (æœªç”Ÿæˆï¼Œå› ä¸ºå·²ä½¿ç”¨ç‰©ç†å€¼ç»˜åˆ¶overall)"
    )
    print(f"  - leadtime_independent_{variable}.png")
    print(f"  - rmse_vs_leadtime_{variable}.png")
    print(f"  - spatial_comparison_{variable}.png")

    # ========================================================================
    # æ€»ç»“
    # ========================================================================
    print("\n" + "=" * 80)
    print("é¢„æµ‹å®Œæˆ!")
    print("=" * 80)

    print(f"\næ¨¡å‹: DIFFUSION ({args.sampling_method.upper()})")
    print(f"æ€»ç»“ (ç‰©ç†ç©ºé—´):")
    print(f"  æ ·æœ¬æ•°: {y_pred.shape[0]}")
    print(f"  RMSE: {metrics_phys['rmse']:.4f} K")
    print(f"  MAE: {metrics_phys['mae']:.4f} K")
    print(f"  ç›¸å…³ç³»æ•°: {metrics_phys['correlation']:.4f}")
    print(f"  SSIM: {metrics_phys['ssim']:.4f}")

    if args.num_samples > 1:
        print(f"\né›†æˆé¢„æµ‹:")
        print(f"  æ ·æœ¬æ•°: {args.num_samples}")
        print(f"  ä¸ç¡®å®šæ€§æ•°æ®å·²ä¿å­˜")

    print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"  - prediction_metrics.json: è¯¦ç»†æŒ‡æ ‡")
    print(f"  - y_pred_*.npy: é¢„æµ‹æ•°æ®")
    print(f"  - *.png: å¯è§†åŒ–å›¾ç‰‡")


if __name__ == "__main__":
    main()
