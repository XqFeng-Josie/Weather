"""
VAEé‡å»ºæµ‹è¯• - è¯„ä¼°Stable Diffusion VAEå¯¹å¤©æ°”æ•°æ®çš„é‡å»ºèƒ½åŠ›

ğŸ“‹ æ–‡ä»¶ä½œç”¨ï¼š
    æµ‹è¯•SD VAEèƒ½å¦å‡†ç¡®åœ°é‡å»ºï¼ˆencode + decodeï¼‰å¤©æ°”å›¾åƒæ•°æ®ã€‚
    ä¸RAEä¿æŒä¸€è‡´ï¼Œä»å›¾åƒç›®å½•åŠ è½½æ•°æ®ã€‚

ğŸ”„ é‡å»ºæµç¨‹ï¼š
    1. ä»å›¾åƒç›®å½•åŠ è½½é¢„å¤„ç†å¥½çš„å¤©æ°”å›¾åƒ
    2. å°†å›¾åƒä»[0, 255]è½¬æ¢ä¸º[-1, 1]ï¼ˆVAEè¾“å…¥èŒƒå›´ï¼‰
    3. VAEé‡å»ºï¼ˆencode + decodeï¼‰
    4. è¯„ä¼°é‡å»ºè´¨é‡å¹¶ç”Ÿæˆå¯è§†åŒ–
    5. ä¿å­˜é‡å»ºPNGä¸ä¸–ç•Œåœ°å›¾ï¼ˆè¾“å‡ºç»“æ„å¯¹é½RAEï¼‰

ğŸ“– ä½¿ç”¨æ–¹æ³•:
    python test_vae_reconstruction.py \
        --data-path weather_images \
        --n-test-samples 100 \
        --save-separate
"""

import argparse
import json
import os
import re
import sys
from pathlib import Path

import numpy as np
import torch
from PIL import Image

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from weatherdiff.vae import SDVAEWrapper, test_vae_reconstruction


# ============================ å…³é”®å¸¸é‡ï¼ˆç¬¦åˆ ERA5 64x32 ç½‘æ ¼ï¼‰ ============================
# æ³¨æ„ï¼šERA5 ç­‰è·æ ¼ç½‘ï¼ˆæ­¤ç‰ˆæœ¬ï¼‰çº¬åº¦å¹¶éæ­£å¥½åˆ° Â±90Â°ï¼Œè€Œæ˜¯ Â±87.1875Â°
LAT_MIN, LAT_MAX = -87.1875, 87.1875
H, W = 32, 64  # (lat x lon)
# ç»åº¦æ˜¯ 0..360ï¼ˆä¸å« 360ï¼‰ï¼Œæ­¥é•¿ 360/64=5.625Â°
LON_0360 = np.linspace(0.0, 360.0, W, endpoint=False)  # 0, 5.625, ..., 354.375
# è½¬ä¸º -180..180ï¼Œå¹¶ç»™å‡ºåˆ—é‡æ’ç´¢å¼•ï¼ˆæŠŠ [180..360) æåˆ°å‰é¢ï¼‰
LON_PM = ((LON_0360 + 180.0) % 360.0) - 180.0
LON_SORT_IDX = np.argsort(LON_PM)  # ä¾æ® -180..180 æ’åºçš„åˆ—ç´¢å¼•ï¼ˆ0Â°ä¼šåœ¨ä¸­é—´ï¼‰
LON_PM_SORTED = LON_PM[LON_SORT_IDX]
# çº¬åº¦æŒ‰ â€œå—åˆ°åŒ—â€ é€’å¢ï¼ˆä¸å¤šæ•°æ•°æ®æ–‡ä»¶ä¸€è‡´ï¼‰
LAT_SN = np.linspace(LAT_MIN, LAT_MAX, H)  # -87.1875 .. +87.1875ï¼ˆå—->åŒ—ï¼‰


def to_plot_array(field_2d: np.ndarray) -> np.ndarray:
    """
    å°†ç½‘æ ¼æ•°æ®è½¬æ¢ä¸º (lat, lon) = (32, 64) æ ¼å¼å¹¶é‡æ’ç»åº¦ï¼Œ
    ä½¿å¾—ç»˜å›¾æ—¶ 0Â° å­åˆçº¿åœ¨ä¸­é—´ã€åŒ—åœ¨ä¸Šã€‚
    å¦‚æœæ•°æ®æ˜¯ (64, 32)ï¼Œè¯´æ˜æ˜¯ (lon, lat) é¡ºåºï¼Œä¼šè‡ªåŠ¨è½¬ç½®ã€‚
    """
    arr = np.array(field_2d)
    # è‡ªåŠ¨ä¿®æ­£ç»´åº¦
    if arr.shape == (64, 32):
        arr = arr.T  # è½¬ç½®ä¸º (32, 64)
    if arr.shape != (32, 64):
        raise ValueError(f"expect (32,64), got {arr.shape}")

    # ç»åº¦é‡æ’ï¼ˆ0â€“360 â†’ -180â€“180ï¼‰
    arr = arr[:, LON_SORT_IDX]
    return arr


def sanitize_component(name: str) -> str:
    """å°†ä»»æ„å­—ç¬¦ä¸²è½¬æ¢ä¸ºå®‰å…¨çš„è·¯å¾„ç»„ä»¶"""
    safe = re.sub(r"[^A-Za-z0-9._-]+", "-", str(name))
    return safe.strip("-") or "default"


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•VAEé‡å»ºèƒ½åŠ›")

    # æ•°æ®å‚æ•°
    parser.add_argument(
        "--data-path",
        type=str,
        required=True,
        help="å›¾åƒç›®å½•è·¯å¾„",
    )

    # VAEå‚æ•°
    parser.add_argument(
        "--model-id",
        type=str,
        default="stable-diffusion-v1-5/stable-diffusion-v1-5",
        help="HuggingFaceæ¨¡å‹ID",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="è®¾å¤‡",
    )

    # æµ‹è¯•å‚æ•°
    parser.add_argument("--n-test-samples", type=int, default=100, help="æµ‹è¯•æ ·æœ¬æ•°é‡")
    parser.add_argument(
        "--output-dir", type=str, default="outputs/vae_reconstruction", help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--save-separate",
        action="store_true",
        help="æ˜¯å¦å°†åŸå›¾å’Œé‡å»ºå›¾åˆ†åˆ«ä¿å­˜åˆ°originalå’Œreconstructedå­æ–‡ä»¶å¤¹",
    )

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    world_map_dir = output_dir / "world_maps"
    world_map_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "=" * 80)
    print("VAEé‡å»ºæµ‹è¯• - E0å®éªŒ: ç›´æ¥ä½¿ç”¨SD VAE")
    print("=" * 80)
    print(f"æ•°æ®è·¯å¾„: {args.data_path}")
    print(f"è®¾å¤‡: {args.device}")

    # åŠ è½½æ•°æ®
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½å’Œé¢„å¤„ç†æ•°æ®")
    print("-" * 80)

    image_dir = Path(args.data_path)
    if not image_dir.exists():
        raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = sorted(image_dir.glob("*.png")) + sorted(image_dir.glob("*.jpg"))
    if len(image_files) == 0:
        raise ValueError(f"åœ¨ {image_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    n_samples = min(args.n_test_samples, len(image_files))
    image_files = image_files[:n_samples]
    
    # åŠ è½½å›¾åƒ
    images = []
    for img_path in image_files:
        img = Image.open(img_path).convert('RGB')
        img_array = np.array(img)  # (H, W, 3)
        # è½¬æ¢ä¸º (C, H, W) å¹¶å½’ä¸€åŒ–åˆ° [-1, 1]
        img_array = img_array.transpose(2, 0, 1)  # (3, H, W)
        img_array = img_array.astype(np.float32) / 255.0  # [0, 1]
        img_array = img_array * 2.0 - 1.0  # [-1, 1]
        images.append(img_array)
    
    test_data = torch.from_numpy(np.stack(images)).float()  # (N, 3, H, W)
    
    # åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    norm_stats_file = image_dir / 'normalization_stats.json'
    if norm_stats_file.exists():
        with open(norm_stats_file, 'r') as f:
            norm_stats = json.load(f)
        print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {norm_stats_file}")
        variable = norm_stats.get('variable', '2m_temperature')
        norm_method = norm_stats.get('method', 'minmax')
    else:
        print("âš  æœªæ‰¾åˆ°å½’ä¸€åŒ–å‚æ•°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        norm_stats = None
        variable = '2m_temperature'
        norm_method = 'minmax'
    
    # åˆ›å»ºnormalizerç”¨äºåå½’ä¸€åŒ–
    class ImageNormalizer:
        def __init__(self, norm_stats=None):
            self.norm_stats = norm_stats
            
        def inverse_transform(self, data, name=None):
            """
            å°†VAEè¾“å‡ºä»[-1, 1]åå½’ä¸€åŒ–åˆ°ç‰©ç†å•ä½
            æµç¨‹: [-1, 1] -> [0, 1] -> ç‰©ç†å•ä½
            """
            # VAEè¾“å‡ºåœ¨[-1, 1]ï¼Œå…ˆè½¬æ¢åˆ°[0, 1]
            data_01 = (data + 1.0) / 2.0  # [-1, 1] -> [0, 1]
            
            if self.norm_stats is None:
                # å¦‚æœæ²¡æœ‰å½’ä¸€åŒ–å‚æ•°ï¼Œå‡è®¾åŸå§‹èŒƒå›´æ˜¯[200, 320] K
                data_orig = data_01 * (320 - 200) + 200
            else:
                method = self.norm_stats.get('method', 'minmax')
                if method == 'minmax':
                    # ä»[0, 1]åå½’ä¸€åŒ–åˆ°åŸå§‹èŒƒå›´
                    orig_min = self.norm_stats.get('original_min')
                    orig_max = self.norm_stats.get('original_max')
                    if orig_min is not None and orig_max is not None:
                        # [0, 1] -> åŸå§‹èŒƒå›´
                        data_orig = data_01 * (orig_max - orig_min) + orig_min
                    else:
                        data_orig = data_01 * (320 - 200) + 200
                else:  # zscore
                    # zscore: ä»[0, 1]åå½’ä¸€åŒ–
                    # å›¾åƒæ˜¯: (z + 3) / 6 * 255ï¼Œæ‰€ä»¥ z = (img/255 * 6) - 3 = (data_01 * 6) - 3
                    orig_mean = self.norm_stats.get('original_mean')
                    orig_std = self.norm_stats.get('original_std')
                    if orig_mean is not None and orig_std is not None:
                        z = data_01 * 6.0 - 3.0
                        data_orig = z * orig_std + orig_mean
                    else:
                        data_orig = data_01 * (320 - 200) + 200
            
            return data_orig
    
    normalizer = ImageNormalizer(norm_stats)
    
    # åŠ¨æ€è·å–å›¾åƒå°ºå¯¸
    H_img, W_img = test_data.shape[2], test_data.shape[3]
    
    print(f"âœ“ ä»å›¾åƒç›®å½•åŠ è½½äº† {len(test_data)} ä¸ªæ ·æœ¬")
    print(f"  å›¾åƒå°ºå¯¸: {H_img}x{W_img}")

    print(f"\næµ‹è¯•æ•°æ® shape: {tuple(test_data.shape)}")
    print(f"æ•°æ®èŒƒå›´: [{test_data.min():.2f}, {test_data.max():.2f}] (VAEè¾“å…¥èŒƒå›´: [-1, 1])")

    # åŠ è½½VAE
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½Stable Diffusion VAE")
    print("-" * 80)

    vae_wrapper = SDVAEWrapper(
        model_id=args.model_id, device=args.device, dtype=torch.float32
    )

    # æµ‹è¯•é‡å»ºï¼ˆå†…éƒ¨ä¼šåš encode/decode ä¸æŒ‡æ ‡è®¡ç®—ï¼‰
    print("\n" + "-" * 80)
    print("Step 3: æµ‹è¯•é‡å»ºèƒ½åŠ›")
    print("-" * 80)

    save_path = output_dir / "vae_reconstruction_results.json"

    metrics = test_vae_reconstruction(
        vae_wrapper=vae_wrapper,
        test_data=test_data,
        normalizer=normalizer,
        variable=variable,
        save_path=str(save_path),
    )

    # ä¿å­˜é‡å»ºå›¾åƒï¼Œæ–¹ä¾¿åç»­å’ŒRAEæµç¨‹å¯¹é½
    print("\n" + "-" * 80)
    print("Step 4: ä¿å­˜é‡å»ºå›¾åƒ (PNG)")
    print("-" * 80)

    recon_root = output_dir / "recon_samples"
    recon_root.mkdir(parents=True, exist_ok=True)
    model_tag = sanitize_component(args.model_id)
    recon_dir = recon_root / model_tag
    recon_dir.mkdir(parents=True, exist_ok=True)
    print(f"é‡å»ºå›¾åƒè¾“å‡ºç›®å½•: {recon_dir}")

    save_batch_size = 8
    total_samples = len(test_data)
    with torch.no_grad():
        for start in range(0, total_samples, save_batch_size):
            end = min(start + save_batch_size, total_samples)
            batch = test_data[start:end]
            batch_recon = vae_wrapper.reconstruct(batch)
            batch_recon = batch_recon.clamp(-1, 1).cpu().numpy()

            for offset, sample in enumerate(batch_recon):
                img_uint8 = np.clip((sample + 1.0) / 2.0 * 255.0, 0, 255).astype(np.uint8)
                img_uint8 = np.transpose(img_uint8, (1, 2, 0))
                original_path = image_files[start + offset]
                filename = f"{Path(original_path).stem}.png"
                Image.fromarray(img_uint8).save(recon_dir / filename)

    print(f"âœ“ å·²ä¿å­˜ {total_samples} å¼ é‡å»ºå›¾ç‰‡è‡³ {recon_dir}")

    # ä¿å­˜ä¸€äº›å¯è§†åŒ–æ ·æœ¬
    print("\n" + "-" * 80)
    print("Step 5: ä¿å­˜å¯è§†åŒ–æ ·æœ¬")
    print("-" * 80)

    n_vis_samples = min(5, len(test_data))
    vis_samples = test_data[:n_vis_samples]

    with torch.no_grad():
        vis_recons = vae_wrapper.reconstruct(vis_samples)

    # åå½’ä¸€åŒ–ç”¨äºå¯è§†åŒ–ï¼ˆè¾“å‡ºå½¢çŠ¶ä¾ç„¶ [N, C, H, W]ï¼‰
    vis_samples_orig = normalizer.inverse_transform(
        vis_samples.numpy(), name=variable
    )
    vis_recons_orig = normalizer.inverse_transform(
        vis_recons.cpu().numpy(), name=variable
    )

    # ===================== ä¿®å¤ï¼šå¹³é¢å¯¹æ¯”å›¾çš„åœ°ç†æ–¹å‘ä¸å±…ä¸­ =====================
    # ç”¨ extent + origin='lower' + ç»åº¦é‡æ’ï¼Œç¡®ä¿â€œä¸ŠåŒ—ä¸‹å—ã€0Â°å±…ä¸­â€
    import matplotlib.pyplot as plt

    def imshow_geo(ax, field_2d, title, cmap="RdBu_r"):
        # é‡æ’ç»åº¦åˆ—ï¼Œä½¿ 0Â° å­åˆçº¿åœ¨ä¸­é—´
        f = to_plot_array(field_2d)  # (H, W) -> (H, W) åˆ—é¡ºåºå˜ä¸º -180..180
        # extent = [lon_min, lon_max, lat_min, lat_max]ï¼›origin='lower' å¯¹åº”å—â†’åŒ—
        extent = [LON_PM_SORTED.min(), LON_PM_SORTED.max(), LAT_SN.min(), LAT_SN.max()]
        im = ax.imshow(
            f,
            extent=extent,
            origin="lower",  # æ•°ç»„ç¬¬0è¡Œï¼ˆå—ç«¯ï¼‰æ”¾åœ¨åº•éƒ¨ -> åŒ—åœ¨ä¸Š
            aspect="auto",
            cmap=cmap,
        )
        ax.set_title(title)
        ax.set_xlabel("Longitude (Â°)")
        ax.set_ylabel("Latitude (Â°)")
        return im

    # ä¿å­˜ numpy æ•°ç»„ï¼ˆç‰©ç†å•ä½ï¼‰
    np.save(output_dir / "samples_original.npy", vis_samples_orig)
    np.save(output_dir / "samples_reconstructed.npy", vis_recons_orig)
    print(f"âœ“ åŸå§‹æ ·æœ¬ä¿å­˜åˆ°: {output_dir / 'samples_original.npy'}")
    print(f"âœ“ é‡å»ºæ ·æœ¬ä¿å­˜åˆ°: {output_dir / 'samples_reconstructed.npy'}")

    # åˆ›å»ºç®€å•å¯¹æ¯”å›¾ï¼ˆå¹³é¢å›¾ï¼Œä½†åæ ‡æ­£ç¡®ï¼‰
    try:
        fig, axes = plt.subplots(n_vis_samples, 3, figsize=(12, 4 * n_vis_samples))
        if n_vis_samples == 1:
            axes = axes[np.newaxis, :]

        for i in range(n_vis_samples):
            gt = vis_samples_orig[i, 0]  # (H,W)
            rc = vis_recons_orig[i, 0]
            err = rc - gt

            im0 = imshow_geo(axes[i, 0], gt, f"Sample {i} - Original")
            im1 = imshow_geo(axes[i, 1], rc, f"Sample {i} - Reconstruction")

            # è¯¯å·®å¯¹é½åŒä¸€è‰²æ ‡ï¼ˆå¯¹ç§°ï¼‰
            vmax = np.abs(err).max() if np.isfinite(err).any() else 1.0
            im2 = imshow_geo(
                axes[i, 2],
                err,
                f"Sample {i} - Error (MAE={np.nanmean(np.abs(err)):.2f})",
            )
            im2.set_clim(-vmax, vmax)

            # æ¯è¡Œç»™è¯¯å·®å›¾åŠ  colorbar
            plt.colorbar(im2, ax=axes[i, 2], fraction=0.046, pad=0.04)

        plt.tight_layout()
        plt.savefig(
            output_dir / "reconstruction_comparison.png", dpi=150, bbox_inches="tight"
        )
        print(f"âœ“ å¯¹æ¯”å›¾ä¿å­˜åˆ°: {output_dir / 'reconstruction_comparison.png'}")
        plt.close()
    except Exception as e:
        print(f"âš  æ— æ³•ç”Ÿæˆå¯è§†åŒ–: {e}")

    # ===================== åˆ†åˆ«ä¿å­˜åŸå›¾å’Œé‡å»ºå›¾åˆ°å­æ–‡ä»¶å¤¹ï¼ˆä¸–ç•Œåœ°å›¾çº¯å›¾ï¼‰ =====================
    if args.save_separate:
        try:
            import cartopy.crs as ccrs
            import cartopy.feature as cfeature

            original_dir = world_map_dir / "original"
            reconstructed_dir = world_map_dir / "reconstructed"
            original_dir.mkdir(parents=True, exist_ok=True)
            reconstructed_dir.mkdir(parents=True, exist_ok=True)

            print(f"\nåˆ†åˆ«ä¿å­˜åŸå›¾å’Œé‡å»ºå›¾ï¼ˆä¸–ç•Œåœ°å›¾çº¯å›¾ï¼‰...")
            print(f"  åŸå›¾ç›®å½•: {original_dir}")
            print(f"  é‡å»ºå›¾ç›®å½•: {reconstructed_dir}")

            # è®¡ç®—ç»Ÿä¸€çš„é¢œè‰²èŒƒå›´ï¼ˆæ‰€æœ‰æ ·æœ¬ï¼‰
            vmin_all = float(np.nanmin(vis_samples_orig[:, 0]))
            vmax_all = float(np.nanmax(vis_samples_orig[:, 0]))

            for i in range(n_vis_samples):
                data_true = vis_samples_orig[i, 0]  # (H, W)
                data_recon = vis_recons_orig[i, 0]  # (H, W)
                
                # å¦‚æœæ˜¯ (64, 32)ï¼Œè¯´æ˜ç»´åº¦åäº†ï¼Œè½¬ç½®å›æ¥
                if data_true.shape == (64, 32):
                    data_true = data_true.T
                    data_recon = data_recon.T
                
                # ç»åº¦æ–¹å‘é‡æ’
                data_true_plot = to_plot_array(data_true)
                data_recon_plot = to_plot_array(data_recon)

                # æ„é€ ç½‘æ ¼ï¼ˆä¸é‡æ’åçš„æ•°æ®ä¸€ä¸€å¯¹åº”ï¼‰
                lon_grid, lat_grid = np.meshgrid(LON_PM_SORTED, LAT_SN)  # (H,W)

                # ä¿å­˜åŸå›¾ï¼ˆçº¯å›¾ï¼Œæ— åæ ‡è½´ã€æ ‡ç­¾ç­‰ï¼‰
                fig = plt.figure(figsize=(16, 8))
                ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())
                ax.set_global()
                ax.contourf(
                    lon_grid,
                    lat_grid,
                    data_true_plot,
                    levels=100,
                    cmap="RdYlBu_r",
                    vmin=vmin_all,
                    vmax=vmax_all,
                    transform=ccrs.PlateCarree(),
                )
                ax.coastlines(linewidth=0.5)
                # å»æ‰æ‰€æœ‰åæ ‡è½´ã€æ ‡ç­¾ã€æ ‡é¢˜
                ax.set_xticks([])
                ax.set_yticks([])
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["bottom"].set_visible(False)
                ax.spines["left"].set_visible(False)
                plt.axis("off")
                plt.savefig(
                    original_dir / f"sample_{i:03d}.png",
                    dpi=300,
                    bbox_inches="tight",
                    pad_inches=0,
                )
                plt.close()

                # ä¿å­˜é‡å»ºå›¾ï¼ˆçº¯å›¾ï¼Œæ— åæ ‡è½´ã€æ ‡ç­¾ç­‰ï¼‰
                fig = plt.figure(figsize=(16, 8))
                ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())
                ax.set_global()
                ax.contourf(
                    lon_grid,
                    lat_grid,
                    data_recon_plot,
                    levels=100,
                    cmap="RdYlBu_r",
                    vmin=vmin_all,
                    vmax=vmax_all,
                    transform=ccrs.PlateCarree(),
                )
                ax.coastlines(linewidth=0.5)
                # å»æ‰æ‰€æœ‰åæ ‡è½´ã€æ ‡ç­¾ã€æ ‡é¢˜
                ax.set_xticks([])
                ax.set_yticks([])
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["bottom"].set_visible(False)
                ax.spines["left"].set_visible(False)
                plt.axis("off")
                plt.savefig(
                    reconstructed_dir / f"sample_{i:03d}.png",
                    dpi=300,
                    bbox_inches="tight",
                    pad_inches=0,
                )
                plt.close()

            print(f"âœ“ å·²ä¿å­˜ {n_vis_samples} ä¸ªæ ·æœ¬çš„åŸå›¾å’Œé‡å»ºå›¾åˆ°å¯¹åº”å­æ–‡ä»¶å¤¹")
        except ImportError:
            print("âš  éœ€è¦å®‰è£…cartopyæ‰èƒ½ç”Ÿæˆä¸–ç•Œåœ°å›¾: pip install cartopy")
        except Exception as e:
            print(f"âš  æ— æ³•åˆ†åˆ«ä¿å­˜åŸå›¾å’Œé‡å»ºå›¾: {e}")

    # ===================== ä¸–ç•Œåœ°å›¾ï¼ˆCartopyï¼‰å¯¹æ¯”ï¼šä¿®å¤ç»çº¬/ä¸­å¿ƒçº¿ =====================
    try:
        import cartopy.crs as ccrs
        import cartopy.feature as cfeature

        print("\nç”Ÿæˆä¸–ç•Œåœ°å›¾å¯¹æ¯”...")

        # é€‰æ‹©ä¸€ä¸ªæ ·æœ¬è¿›è¡Œä¸–ç•Œåœ°å›¾å¯è§†åŒ–
        sample_idx = 0
        data_true = vis_samples_orig[sample_idx, 0]  # (H, W)
        data_recon = vis_recons_orig[sample_idx, 0]  # (H, W)
        # å¦‚æœæ˜¯ (64, 32)ï¼Œè¯´æ˜ç»´åº¦åäº†ï¼Œè½¬ç½®å›æ¥
        if data_true.shape == (64, 32):
            data_true = data_true.T
            data_recon = data_recon.T
        # ä»…ç»åº¦æ–¹å‘é‡æ’ï¼›çº¬åº¦ä½¿ç”¨å—->åŒ—çš„çœŸå®å–å€¼ï¼Œæ— éœ€ç¿»è½¬
        data_true_plot = to_plot_array(data_true)
        data_recon_plot = to_plot_array(data_recon)

        # æ„é€ ç½‘æ ¼ï¼ˆä¸é‡æ’åçš„æ•°æ®ä¸€ä¸€å¯¹åº”ï¼‰
        lon_grid, lat_grid = np.meshgrid(LON_PM_SORTED, LAT_SN)  # (H,W)

        # ç»Ÿä¸€é¢œè‰²èŒƒå›´
        vmin = float(np.nanmin([data_true_plot.min(), data_recon_plot.min()]))
        vmax = float(np.nanmax([data_true_plot.max(), data_recon_plot.max()]))

        fig = plt.figure(figsize=(24, 10))

        # ========== å·¦å›¾: Ground Truth ==========
        ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())
        ax1.set_global()
        im1 = ax1.contourf(
            lon_grid,
            lat_grid,
            data_true_plot,
            levels=100,
            cmap="RdYlBu_r",
            vmin=vmin,
            vmax=vmax,
            transform=ccrs.PlateCarree(),
        )
        ax1.coastlines(linewidth=0.6)
        ax1.add_feature(cfeature.BORDERS, linestyle=":", linewidth=0.5)
        gl1 = ax1.gridlines(
            draw_labels=True, x_inline=False, y_inline=False, linewidth=0.5, alpha=0.5
        )
        ax1.set_title("Ground Truth", fontsize=16, fontweight="bold", pad=10)
        cbar1 = plt.colorbar(
            im1, ax=ax1, orientation="horizontal", pad=0.05, shrink=0.8
        )
        cbar1.set_label("Temperature (K)", fontsize=12)

        # ========== å³å›¾: Reconstruction ==========
        ax2 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())
        ax2.set_global()
        im2 = ax2.contourf(
            lon_grid,
            lat_grid,
            data_recon_plot,
            levels=100,
            cmap="RdYlBu_r",
            vmin=vmin,
            vmax=vmax,
            transform=ccrs.PlateCarree(),
        )
        ax2.coastlines(linewidth=0.6)
        ax2.add_feature(cfeature.BORDERS, linestyle=":", linewidth=0.5)
        gl2 = ax2.gridlines(
            draw_labels=True, x_inline=False, y_inline=False, linewidth=0.5, alpha=0.5
        )
        ax2.set_title("Reconstruction", fontsize=16, fontweight="bold", pad=10)
        cbar2 = plt.colorbar(
            im2, ax=ax2, orientation="horizontal", pad=0.05, shrink=0.8
        )
        cbar2.set_label("Temperature (K)", fontsize=12)

        # è¯¯å·®ç»Ÿè®¡
        err = data_recon_plot - data_true_plot
        rmse = float(np.sqrt(np.nanmean(err**2)))
        mae = float(np.nanmean(np.abs(err)))

        fig.suptitle(
            f"{variable} - VAE Reconstruction Comparison\n"
            f"Sample {sample_idx} | RMSE: {rmse:.2f} K | MAE: {mae:.2f} K",
            fontsize=18,
            fontweight="bold",
            y=0.98,
        )
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        out_map = world_map_dir / "spatial_reconstruction_comparison.png"
        plt.savefig(out_map, dpi=300, bbox_inches="tight")
        print(f"âœ“ ä¸–ç•Œåœ°å›¾å¯¹æ¯”ä¿å­˜åˆ°: {out_map}")
        plt.close()

    except ImportError:
        print("âš  éœ€è¦å®‰è£…cartopyæ‰èƒ½ç”Ÿæˆä¸–ç•Œåœ°å›¾: pip install cartopy")
    except Exception as e:
        print(f"âš  æ— æ³•ç”Ÿæˆä¸–ç•Œåœ°å›¾: {e}")

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print(f"\næ€»ç»“:")
    print(f"  RMSE: {metrics['rmse']:.4f} (åŸå§‹å°ºåº¦)")
    print(f"  MAE: {metrics['mae']:.4f}")
    print(f"  SSIM: {metrics['ssim']:.4f}")
    print(f"  ç›¸å…³ç³»æ•°: {metrics['correlation']:.4f}")

    # ç»™å‡ºå»ºè®®
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    if metrics["rmse"] < 5.0 and metrics["correlation"] > 0.9:
        print("  âœ“ VAEé‡å»ºè´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç”¨äºåç»­æ­¥éª¤")
        print("  â†’ ç»§ç»­ Step 3: è®­ç»ƒå›¾åƒåˆ°å›¾åƒé¢„æµ‹æ¨¡å‹")
    elif metrics["rmse"] < 10.0:
        print("  âš  VAEé‡å»ºè´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®è€ƒè™‘:")
        print("    1. å¾®è°ƒVAE (E1å®éªŒ)")
        print("    2. è®­ç»ƒè‡ªå®šä¹‰VAE (E2å®éªŒ)")
    else:
        print("  âœ— VAEé‡å»ºè´¨é‡è¾ƒå·®ï¼Œå¼ºçƒˆå»ºè®®:")
        print("    1. è®­ç»ƒè‡ªå®šä¹‰VAE (E2å®éªŒ)")
        print("    2. æˆ–ç›´æ¥åœ¨åƒç´ ç©ºé—´å»ºæ¨¡")


if __name__ == "__main__":
    main()
