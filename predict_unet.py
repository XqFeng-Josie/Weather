"""
U-Netç»Ÿä¸€é¢„æµ‹è„šæœ¬ - æ”¯æŒåƒç´ ç©ºé—´å’Œæ½œç©ºé—´ä¸¤ç§æ¨¡å¼

ğŸ“‹ æ–‡ä»¶ä½œç”¨:
    å¯¹è®­ç»ƒå¥½çš„U-Netæ¨¡å‹ï¼ˆåƒç´ ç©ºé—´æˆ–æ½œç©ºé—´ï¼‰è¿›è¡Œé¢„æµ‹ï¼Œç”Ÿæˆè¯„ä¼°æŒ‡æ ‡å’Œå¯è§†åŒ–å›¾ç‰‡ã€‚
    
ğŸ”„ é¢„æµ‹æµç¨‹:
    1. æ ¹æ®modeå‚æ•°é€‰æ‹©åƒç´ ç©ºé—´æˆ–æ½œç©ºé—´æ¨¡å¼
    2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé…ç½®
    3. åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    4. ã€æ½œç©ºé—´ã€‘åŠ è½½VAEæ¨¡å‹
    5. åŠ è½½æµ‹è¯•æ•°æ®
    6. ç”Ÿæˆé¢„æµ‹
       ã€æ½œç©ºé—´ã€‘VAEåˆ†æ‰¹ç¼–ç ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
       ã€æ½œç©ºé—´ã€‘U-Netæ½œç©ºé—´é¢„æµ‹
       ã€æ½œç©ºé—´ã€‘VAEåˆ†æ‰¹è§£ç å›åƒç´ ç©ºé—´
    7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå½’ä¸€åŒ–ç©ºé—´ + ç‰©ç†ç©ºé—´ï¼‰
    8. ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ—¶é—´åºåˆ—å›¾ + ä¸–ç•Œåœ°å›¾å¯¹æ¯”ï¼‰
    9. ä¿å­˜æ‰€æœ‰ç»“æœ
    
âš¡ æ˜¾å­˜ä¼˜åŒ–:
    ä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç ç­–ç•¥ï¼ˆä¸train_latent_unet.pyä¸€è‡´ï¼‰
    - é¿å…ä¸€æ¬¡æ€§å¤„ç†å¤§é‡å›¾åƒå¯¼è‡´æ˜¾å­˜æº¢å‡º
    - é»˜è®¤vae_batch_size=4ï¼Œé€‚åˆ12GB GPU
    - å¯æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ï¼ˆ6GBç”¨2ï¼Œ24GBç”¨8ï¼‰

ğŸ“Š è¾“å‡ºæ–‡ä»¶:
    - prediction_metrics.json: è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
    - y_pred_*.npy: é¢„æµ‹æ•°æ®ï¼ˆå½’ä¸€åŒ– + ç‰©ç†å•ä½ï¼‰
    - y_true_*.npy: çœŸå€¼æ•°æ®
    - timeseries_*.png: æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
    - spatial_comparison_*.png: ä¸–ç•Œåœ°å›¾å¯¹æ¯”å›¾ â­
    - rmse_vs_leadtime_*.png: RMSEéšé¢„æµ‹æ­¥é•¿å˜åŒ–

ğŸ“– ä½¿ç”¨æ–¹æ³•:
    # åƒç´ ç©ºé—´U-Neté¢„æµ‹
    python predict_unet.py --mode pixel \\
        --model-dir outputs/pixel_unet \\
        --time-slice 2020-02-01:2020-02-10
    
    # æ½œç©ºé—´U-Neté¢„æµ‹ï¼ˆæ¨èé…ç½®ï¼‰
    python predict_unet.py --mode latent \\
        --model-dir outputs/latent_unet \\
        --time-slice 2020-02-01:2020-02-10 \\
        --batch-size 32 \\
        --vae-batch-size 4  # æ§åˆ¶æ˜¾å­˜å ç”¨
    
    # æ˜¾å­˜ä¸è¶³æ—¶è°ƒæ•´
    python predict_unet.py --mode latent \\
        --model-dir outputs/latent_unet \\
        --batch-size 16 \\
        --vae-batch-size 2  # å‡å°VAEæ‰¹æ¬¡

ğŸ¯ é¢„æœŸæ•ˆæœ:
    åƒç´ ç©ºé—´U-Net:
        - RMSE: 1-3K
        - ç›¸å…³ç³»æ•°: > 0.995
        - SSIM: > 0.995
    
    æ½œç©ºé—´U-Net:
        - RMSE: 2-5K
        - ç›¸å…³ç³»æ•°: > 0.99
        - SSIM: > 0.99
"""

import argparse
import torch
import numpy as np
import json
import pickle
from pathlib import Path
from tqdm import tqdm

from weatherdiff.unet import WeatherUNet, LatentUNet
from weatherdiff.vae import SDVAEWrapper
from weatherdiff.utils import WeatherDataModule, calculate_metrics, format_metrics
from src.visualization import visualize_predictions_improved


def detect_lon_first(data_array):
    """
    åˆ¤æ–­æ•°æ®çš„ç©ºé—´ç»´åº¦é¡ºåºæ˜¯å¦ä¸º (lon, lat)
    
    Args:
        data_array: xarray DataArray
    
    Returns:
        True  -> ç©ºé—´é¡ºåºä¸º (lon, lat)
        False -> ç©ºé—´é¡ºåºä¸º (lat, lon)
        None  -> æ— æ³•åˆ¤æ–­ï¼ˆç¼ºå°‘ç»´åº¦åç§°ï¼‰
    """
    dims = list(getattr(data_array, 'dims', []))
    if not dims:
        return None
    
    lat_dim = next((dim for dim in dims if 'lat' in dim.lower()), None)
    lon_dim = next((dim for dim in dims if 'lon' in dim.lower()), None)
    
    if lat_dim is None or lon_dim is None:
        return None
    
    lat_idx = dims.index(lat_dim)
    lon_idx = dims.index(lon_dim)
    
    return lon_idx < lat_idx


def encode_in_batches(vae_wrapper, images, vae_batch_size=4, device='cuda'):
    """
    åˆ†æ‰¹ç¼–ç å›¾åƒåˆ°æ½œç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    
    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        images: (N, C, H, W) å›¾åƒtensor (åœ¨CPUä¸Š)
        vae_batch_size: VAEç¼–ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
    
    Returns:
        latents: (N, 4, H//8, W//8) æ½œå‘é‡
    """
    N = images.shape[0]
    latent_list = []
    
    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = images[i:end_idx].to(device)
        latent_batch = vae_wrapper.encode(batch)
        latent_list.append(latent_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜
        
        # æ¸…ç†æ˜¾å­˜
        del batch, latent_batch
        torch.cuda.empty_cache()
    
    # åˆå¹¶æ‰€æœ‰batch
    latents = torch.cat(latent_list, dim=0).to(device)
    return latents


def decode_in_batches(vae_wrapper, latents, vae_batch_size=4, device='cuda'):
    """
    åˆ†æ‰¹è§£ç æ½œå‘é‡åˆ°åƒç´ ç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
    
    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        latents: (N, 4, H//8, W//8) æ½œå‘é‡tensor (åœ¨CPUä¸Š)
        vae_batch_size: VAEè§£ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
    
    Returns:
        images: (N, 3, H, W) å›¾åƒ
    """
    N = latents.shape[0]
    image_list = []
    
    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = latents[i:end_idx].to(device)
        image_batch = vae_wrapper.decode(batch)
        image_list.append(image_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜
        
        # æ¸…ç†æ˜¾å­˜
        del batch, image_batch
        torch.cuda.empty_cache()
    
    # åˆå¹¶æ‰€æœ‰batch
    images = torch.cat(image_list, dim=0).to(device)
    return images


def predict_pixel_unet(args):
    """åƒç´ ç©ºé—´U-Neté¢„æµ‹"""
    
    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "=" * 80)
    print("åƒç´ ç©ºé—´U-Neté¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)
    
    config_path = model_dir / 'config.json'
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")
    
    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / 'normalizer_stats.pkl'
    with open(normalizer_path, 'rb') as f:
        normalizer_data = pickle.load(f)
    
    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")
    
    # ========================================================================
    # Step 2: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½æ•°æ®")
    print("-" * 80)
    
    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from torch.utils.data import DataLoader
    from weatherdiff.utils import prepare_weather_data, WeatherSequenceDataset, Normalizer
    
    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)
    
    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(':')
    ds = ds.sel(time=slice(start, end))
    
    # è·å–å˜é‡æ•°æ®
    variable_da = ds[config['variable']]
    lon_first_flag = detect_lon_first(variable_da)
    if lon_first_flag is not None:
        config['_spatial_lon_first'] = lon_first_flag
        orientation_desc = "Longitude-First (lon->lat)" if lon_first_flag else "Latitude-First (lat->lon)"
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: {orientation_desc} | dims={variable_da.dims}")
    else:
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: æœªæ£€æµ‹åˆ°çº¬/ç»åº¦åç§° | dims={variable_da.dims}")
    data = variable_da.values  # (Time, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")
    
    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(data, 
                                n_channels=config['n_channels'],
                                target_size=None)
    print(f"å¤„ç†å shape: {data.shape}")
    
    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config['normalization'])
    normalizer.load_stats(normalizer_data['stats'])
    data = normalizer.transform(data, name=config['variable'])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    
    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, 
        config['input_length'], 
        config['output_length']
    )
    
    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # ========================================================================
    # Step 3: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ¨¡å‹")
    print("-" * 80)
    
    # è·å–æ•°æ®å½¢çŠ¶ä¿¡æ¯
    sample_input, sample_output = full_dataset[0]
    T_in, C, H, W = sample_input.shape
    T_out = sample_output.shape[0]
    
    in_channels = T_in * C
    out_channels = T_out * C
    
    model = WeatherUNet(
        in_channels=in_channels,
        out_channels=out_channels,
        base_channels=config['base_channels'],
        depth=config['depth']
    )
    
    checkpoint_path = model_dir / 'best_model.pt'
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(args.device)
    model.eval()
    
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========================================================================
    # Step 4: é¢„æµ‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: ç”Ÿæˆé¢„æµ‹")
    print("-" * 80)
    
    all_predictions = []
    all_targets = []
    all_inputs = []
    
    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc='é¢„æµ‹ä¸­'):
            inputs = inputs.to(args.device)
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]
            
            # å±•å¹³æ—¶é—´ç»´åº¦
            inputs_flat = inputs.reshape(B, T_in * C, H, W)
            outputs = model(inputs_flat)
            outputs = outputs.reshape(B, T_out, C, H, W)
            
            all_predictions.append(outputs.cpu().numpy())
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())
    
    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)
    
    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")
    
    return y_pred, y_true, normalizer, config, output_dir


def predict_latent_unet(args):
    """æ½œç©ºé—´U-Neté¢„æµ‹"""
    
    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "=" * 80)
    print("æ½œç©ºé—´U-Neté¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)
    
    config_path = model_dir / 'config.json'
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")
    print(f"  VAEæ¨¡å‹: {config['vae_model_id']}")
    
    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / 'normalizer_stats.pkl'
    with open(normalizer_path, 'rb') as f:
        normalizer_data = pickle.load(f)
    
    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")
    
    # ========================================================================
    # Step 2: åŠ è½½VAE
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½VAE")
    print("-" * 80)
    
    vae_wrapper = SDVAEWrapper(
        model_id=config['vae_model_id'],
        device=args.device
    )
    print(f"âœ“ VAEåŠ è½½å®Œæˆ")
    
    # ========================================================================
    # Step 3: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ•°æ®")
    print("-" * 80)
    
    # è§£ætarget_size
    target_size = tuple(map(int, config['target_size'].split(',')))
    
    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from torch.utils.data import DataLoader
    from weatherdiff.utils import prepare_weather_data, WeatherSequenceDataset, Normalizer
    
    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)
    
    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(':')
    ds = ds.sel(time=slice(start, end))
    
    # è·å–å˜é‡æ•°æ®
    variable_da = ds[config['variable']]
    lon_first_flag = detect_lon_first(variable_da)
    if lon_first_flag is not None:
        config['_spatial_lon_first'] = lon_first_flag
        orientation_desc = "Longitude-First (lon->lat)" if lon_first_flag else "Latitude-First (lat->lon)"
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: {orientation_desc} | dims={variable_da.dims}")
    else:
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: æœªæ£€æµ‹åˆ°çº¬/ç»åº¦åç§° | dims={variable_da.dims}")
    data = variable_da.values  # (Time, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")
    
    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(data, 
                                n_channels=3,
                                target_size=target_size)
    print(f"å¤„ç†å shape: {data.shape}")
    print(f"  å›¾åƒå°ºå¯¸: {target_size}")
    print(f"  æ½œå‘é‡å°ºå¯¸: ({target_size[0]//8}, {target_size[1]//8})")
    
    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config['normalization'])
    normalizer.load_stats(normalizer_data['stats'])
    data = normalizer.transform(data, name=config['variable'])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    
    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, 
        config['input_length'], 
        config['output_length']
    )
    
    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # ========================================================================
    # Step 4: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: åŠ è½½æ¨¡å‹")
    print("-" * 80)
    
    # è·å–æ•°æ®å½¢çŠ¶ä¿¡æ¯
    sample_input, _ = full_dataset[0]
    T_in = sample_input.shape[0]
    T_out = config['output_length']
    
    model = LatentUNet(
        input_length=config['input_length'],
        output_length=config['output_length'],
        latent_channels=4,  # SD VAEå›ºå®šä¸º4
        base_channels=config['base_channels'],
        depth=config['depth']
    )
    
    checkpoint_path = model_dir / 'best_model.pt'
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(args.device)
    model.eval()
    
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========================================================================
    # Step 5: é¢„æµ‹ï¼ˆæ½œç©ºé—´ -> åƒç´ ç©ºé—´ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 5: ç”Ÿæˆé¢„æµ‹ (ä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç )")
    print("-" * 80)
    
    vae_batch_size = args.vae_batch_size
    print(f"  VAE batch size: {vae_batch_size} (æ§åˆ¶æ˜¾å­˜å ç”¨)")
    
    all_predictions = []
    all_targets = []
    all_inputs = []
    
    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc='é¢„æµ‹ä¸­(æ½œç©ºé—´)'):
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]
            
            # ç¼–ç åˆ°æ½œç©ºé—´ï¼ˆåˆ†æ‰¹å¤„ç†é¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            inputs_flat = inputs.reshape(B * T_in, C, H, W)
            latent_inputs = encode_in_batches(
                vae_wrapper, inputs_flat, vae_batch_size, args.device
            )
            latent_inputs = latent_inputs.reshape(B, T_in, 4, H // 8, W // 8)
            
            # æ½œç©ºé—´é¢„æµ‹ï¼ˆLatentUNetæœŸæœ›5ç»´è¾“å…¥ï¼‰
            latent_outputs = model(latent_inputs)
            
            # è§£ç å›åƒç´ ç©ºé—´ï¼ˆåˆ†æ‰¹å¤„ç†é¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            latent_outputs_flat = latent_outputs.reshape(B * T_out, 4, H // 8, W // 8)
            outputs = decode_in_batches(
                vae_wrapper, latent_outputs_flat.cpu(), vae_batch_size, args.device
            )
            outputs = outputs.reshape(B, T_out, C, H, W)
            
            all_predictions.append(outputs.cpu().numpy())
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())
    
    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)
    
    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")
    
    return y_pred, y_true, normalizer, config, output_dir


def main():
    parser = argparse.ArgumentParser(description='U-Netç»Ÿä¸€é¢„æµ‹è„šæœ¬')
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument('--mode', type=str, required=True, choices=['pixel', 'latent'],
                       help='é¢„æµ‹æ¨¡å¼: pixel=åƒç´ ç©ºé—´, latent=æ½œç©ºé—´')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model-dir', type=str, required=True,
                       help='æ¨¡å‹ç›®å½•ï¼ˆåŒ…å«best_model.ptå’Œconfig.jsonï¼‰')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data-path', type=str,
                       default='gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr',
                       help='æ•°æ®è·¯å¾„')
    parser.add_argument('--time-slice', type=str, default='2020-01-01:2020-12-31',
                       help='é¢„æµ‹æ—¶é—´èŒƒå›´')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹ç›®å½•ï¼‰')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='é¢„æµ‹æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--vae-batch-size', type=int, default=4,
                       help='VAEç¼–ç /è§£ç æ‰¹æ¬¡å¤§å°ï¼ˆä»…latentæ¨¡å¼ï¼Œæ§åˆ¶æ˜¾å­˜å ç”¨ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str,
                       default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='è®¾å¤‡')
    
    args = parser.parse_args()
    
    # ========================================================================
    # æ ¹æ®æ¨¡å¼é€‰æ‹©é¢„æµ‹æ–¹æ³•
    # ========================================================================
    if args.mode == 'pixel':
        y_pred, y_true, normalizer, config, output_dir = predict_pixel_unet(args)
    else:
        y_pred, y_true, normalizer, config, output_dir = predict_latent_unet(args)
    
    # ========================================================================
    # Step 6: åå½’ä¸€åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 6: è¯„ä¼°å’Œåå½’ä¸€åŒ–")
    print("-" * 80)
    
    # å½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡
    print("\nå½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡:")
    metrics_norm = calculate_metrics(y_pred, y_true, ensemble=False)
    print(format_metrics(metrics_norm))
    
    # åå½’ä¸€åŒ–åˆ°ç‰©ç†å•ä½
    variable = config['variable']
    C = y_pred.shape[2]
    H = y_pred.shape[3]
    W = y_pred.shape[4]
    
    y_pred_flat = y_pred.reshape(-1, C, H, W)
    y_true_flat = y_true.reshape(-1, C, H, W)
    
    y_pred_phys = normalizer.inverse_transform(y_pred_flat, name=variable)
    y_true_phys = normalizer.inverse_transform(y_true_flat, name=variable)
    
    y_pred_phys = y_pred_phys.reshape(y_pred.shape)
    y_true_phys = y_true_phys.reshape(y_true.shape)
    
    print("\nâœ“ åå½’ä¸€åŒ–å®Œæˆ")
    print(f"  é¢„æµ‹èŒƒå›´: [{y_pred_phys.min():.2f}, {y_pred_phys.max():.2f}] K")
    print(f"  çœŸå€¼èŒƒå›´: [{y_true_phys.min():.2f}, {y_true_phys.max():.2f}] K")
    
    # ç‰©ç†ç©ºé—´çš„æŒ‡æ ‡
    print("\nç‰©ç†ç©ºé—´çš„æŒ‡æ ‡ (åŸå§‹å°ºåº¦):")
    metrics_phys = calculate_metrics(y_pred_phys, y_true_phys, ensemble=False)
    print(format_metrics(metrics_phys))
    
    # è®¡ç®—æ¯ä¸ªlead timeçš„RMSE
    print("\næ¯ä¸ªlead timeçš„RMSE:")
    T_out = y_pred_phys.shape[1]
    rmse_per_leadtime = {}
    for t in range(T_out):
        y_pred_t = y_pred_phys[:, t, :, :, :]  # (N, C, H, W)
        y_true_t = y_true_phys[:, t, :, :, :]
        rmse_t = np.sqrt(np.mean((y_pred_t - y_true_t) ** 2))
        rmse_per_leadtime[f'rmse_step_{t+1}'] = float(rmse_t)
        print(f"  Step {t+1} ({(t+1)*6}h): {rmse_t:.4f} K")
    
    # ========================================================================
    # Step 7: ä¿å­˜ç»“æœ
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 7: ä¿å­˜ç»“æœ")
    print("-" * 80)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_all = {
        'mode': args.mode,
        'normalized_space': {k: float(v) for k, v in metrics_norm.items()},
        'physical_space': {k: float(v) for k, v in metrics_phys.items()},
        'physical_space_rmse_per_leadtime': rmse_per_leadtime,
        'time_slice': args.time_slice,
        'n_samples': int(y_pred.shape[0])
    }
    
    metrics_path = output_dir / 'prediction_metrics.json'
    with open(metrics_path, 'w') as f:
        json.dump(metrics_all, f, indent=2)
    print(f"âœ“ æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")
    
    # ä¿å­˜é¢„æµ‹æ•°æ®
    pred_dir = output_dir / "predictions_data"
    pred_dir.mkdir(exist_ok=True)
    np.save(pred_dir / 'y_test_pred_norm.npy', y_pred)
    np.save(pred_dir / 'y_test_norm.npy', y_true)
    np.save(pred_dir / 'y_test.npy', y_true_phys)  # çœŸå€¼
    np.save(pred_dir / 'y_test_pred.npy', y_pred_phys)  # é¢„æµ‹å€¼
    print(f"âœ“ é¢„æµ‹æ•°æ®å·²ä¿å­˜: {pred_dir}/y_*.npy")
    
    # ========================================================================
    # Step 8: ç”Ÿæˆå¯è§†åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 8: ç”Ÿæˆå¯è§†åŒ–")
    print("-" * 80)
    
    # è·å–ç©ºé—´åæ ‡
    import xarray as xr
    ds = xr.open_zarr(args.data_path)
    
    spatial_coords = None
    lon_first_flag = config.get('_spatial_lon_first')
    if hasattr(ds, 'latitude') and hasattr(ds, 'longitude'):
        lat_values = ds.latitude.values
        lon_values = ds.longitude.values
        
        # è·å–é¢„æµ‹æ•°æ®çš„å®é™…ç©ºé—´å½¢çŠ¶
        # y_pred_phys shape: (N, T, C, H, W)
        actual_H = y_pred_phys.shape[3]
        actual_W = y_pred_phys.shape[4]
        
        print(f"\næ£€æŸ¥ç©ºé—´åæ ‡:")
        print(f"  æ•°æ®é›†åæ ‡: lat={len(lat_values)}, lon={len(lon_values)}")
        print(f"  é¢„æµ‹æ•°æ®å½¢çŠ¶: H={actual_H}, W={actual_W}")
        
        orientation_handled = False
        if lon_first_flag is True:
            print("  æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®ä¸º Longitude-Firstï¼ˆlon->latï¼‰ï¼Œä¸ºå¯è§†åŒ–è½¬ç½®ä¸€æ¬¡")
            y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
            y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))
            orientation_handled = True
            actual_H = y_pred_phys.shape[3]
            actual_W = y_pred_phys.shape[4]
            print(f"  è½¬ç½®å: H={actual_H}(lat), W={actual_W}(lon)")
        elif lon_first_flag is False:
            print("  æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®ä¸º Latitude-Firstï¼ˆlat->lonï¼‰ï¼Œæ— éœ€é¢å¤–å¤„ç†")
            orientation_handled = True
        else:
            print("  æœªèƒ½ä»é…ç½®ç¡®å®šç©ºé—´é¡ºåºï¼Œå°è¯•æ ¹æ®åæ ‡é•¿åº¦æ¨æ–­...")
        
        if not orientation_handled:
            # ä½¿ç”¨åæ ‡é•¿åº¦è¿›è¡Œå›é€€æ¨æ–­
            if len(lon_values) == actual_H and len(lat_values) == actual_W:
                print(f"  âœ“ åæ ‡åŒ¹é… (ERA5æ ¼å¼: H={actual_H}(lon), W={actual_W}(lat))")
                print(f"  è½¬ç½®ç©ºé—´ç»´åº¦ä»¥é€‚é…visualization (H<->W)")
                
                y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
                y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))
                actual_H = y_pred_phys.shape[3]
                actual_W = y_pred_phys.shape[4]
                print(f"  è½¬ç½®å: H={actual_H}(lat), W={actual_W}(lon)")
            elif len(lat_values) == actual_H and len(lon_values) == actual_W:
                print(f"  âœ“ åæ ‡åŒ¹é… (æ ‡å‡†æ ¼å¼: H={actual_H}(lat), W={actual_W}(lon))")
            else:
                print(f"  âš  åæ ‡ç»´åº¦ä¸åŒ¹é… (lat:{len(lat_values)}, lon:{len(lon_values)} vs H:{actual_H}, W:{actual_W})")
        
        # æ ¹æ®æœ€ç»ˆçš„ç©ºé—´å½¢çŠ¶é€‰æ‹©åæ ‡
        if len(lat_values) == y_pred_phys.shape[3] and len(lon_values) == y_pred_phys.shape[4]:
            spatial_coords = {
                'lat': lat_values,
                'lon': lon_values,
            }
        else:
            # å°ºå¯¸å®Œå…¨ä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤åæ ‡
            print(f"  ä½¿ç”¨é»˜è®¤åæ ‡ç”Ÿæˆå¯è§†åŒ– ({y_pred_phys.shape[3]}x{y_pred_phys.shape[4]}) ...")
            spatial_coords = {
                'lat': np.linspace(-90, 90, y_pred_phys.shape[3]),
                'lon': np.linspace(0, 360, y_pred_phys.shape[4]),
            }
    
    # ç”Ÿæˆå¯è§†åŒ–
    # æ³¨æ„ï¼šWeatherDiffä½¿ç”¨minmaxå½’ä¸€åŒ–ï¼ˆ[-1,1]ï¼‰ï¼Œä¸ä¼ ç»Ÿæ¨¡å‹çš„zscoreä¸åŒ
    # è¿™é‡Œä¼ é€’å·²ç»åå½’ä¸€åŒ–çš„ç‰©ç†å€¼æ•°æ®ï¼Œnorm_params=None
    # å¯è§†åŒ–å‡½æ•°ä¼šç”Ÿæˆtimeseries_overallï¼ˆç‰©ç†å€¼ï¼‰ï¼Œä½†ä¸ä¼šç”Ÿæˆtimeseries_physical
    # ï¼ˆå› ä¸ºWeatherDiffçš„å½’ä¸€åŒ–æ–¹å¼ä¸å¯è§†åŒ–å‡½æ•°é¢„æœŸä¸å…¼å®¹ï¼‰
    visualize_predictions_improved(
        y_true_phys,           # y_test (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        y_pred_phys,           # y_test_pred (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        metrics_phys,          # test_metrics (ç‰©ç†ç©ºé—´æŒ‡æ ‡)
        [variable],            # variables
        f'{args.mode}_unet',   # model_name
        output_dir,            # output_dir
        'spatial',             # data_format
        norm_params=None,      # norm_params (ä¸æä¾›ï¼Œå› ä¸ºå½’ä¸€åŒ–æ–¹å¼ä¸åŒ)
        spatial_coords=spatial_coords  # spatial_coords
    )
    
    print(f"âœ“ å¯è§†åŒ–å·²ç”Ÿæˆ")
    print(f"  - timeseries_overall_{variable}.png (ç‰©ç†å€¼)")
    print(f"  - timeseries_physical_{variable}.png (æœªç”Ÿæˆï¼Œå› ä¸ºå·²ä½¿ç”¨ç‰©ç†å€¼ç»˜åˆ¶overall)") 
    print(f"  - leadtime_independent_{variable}.png")
    print(f"  - rmse_vs_leadtime_{variable}.png")
    print(f"  - spatial_comparison_{variable}.png")
    
    # ========================================================================
    # æ€»ç»“
    # ========================================================================
    print("\n" + "=" * 80)
    print("é¢„æµ‹å®Œæˆ!")
    print("=" * 80)
    
    print(f"\næ¨¡å¼: {args.mode.upper()}")
    print(f"æ€»ç»“ (ç‰©ç†ç©ºé—´):")
    print(f"  æ ·æœ¬æ•°: {y_pred.shape[0]}")
    print(f"  RMSE: {metrics_phys['rmse']:.4f} K")
    print(f"  MAE: {metrics_phys['mae']:.4f} K")
    print(f"  ç›¸å…³ç³»æ•°: {metrics_phys['correlation']:.4f}")
    print(f"  SSIM: {metrics_phys['ssim']:.4f}")
    
    print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"  - prediction_metrics.json: è¯¦ç»†æŒ‡æ ‡")
    print(f"  - y_pred_*.npy: é¢„æµ‹æ•°æ®")
    print(f"  - *.png: å¯è§†åŒ–å›¾ç‰‡")
    
    # æ€§èƒ½è¯„ä»·
    if metrics_phys['rmse'] < 3.0:
        print("\nâœ… é¢„æµ‹æ•ˆæœä¼˜ç§€ï¼")
    elif metrics_phys['rmse'] < 5.0:
        print("\nâœ… é¢„æµ‹æ•ˆæœè‰¯å¥½ï¼")
    elif metrics_phys['rmse'] < 10.0:
        print("\nâš ï¸  é¢„æµ‹æ•ˆæœä¸€èˆ¬")
    else:
        print("\nâš ï¸  é¢„æµ‹æ•ˆæœè¾ƒå·®ï¼Œå»ºè®®:")
        print("  1. å¢åŠ è®­ç»ƒæ•°æ®é‡")
        print("  2. å¢åŠ è®­ç»ƒè½®æ•°")
        print("  3. è°ƒæ•´æ¨¡å‹å‚æ•°")


if __name__ == '__main__':
    main()
