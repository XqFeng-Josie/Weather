"""
U-Netç»Ÿä¸€é¢„æµ‹è„šæœ¬ - æ”¯æŒåƒç´ ç©ºé—´å’Œæ½œç©ºé—´ä¸¤ç§æ¨¡å¼

ğŸ“‹ æ–‡ä»¶ä½œç”¨:
    å¯¹è®­ç»ƒå¥½çš„U-Netæ¨¡å‹ï¼ˆåƒç´ ç©ºé—´æˆ–æ½œç©ºé—´ï¼‰è¿›è¡Œé¢„æµ‹ï¼Œç”Ÿæˆè¯„ä¼°æŒ‡æ ‡å’Œå¯è§†åŒ–å›¾ç‰‡ã€‚
    
ğŸ”„ é¢„æµ‹æµç¨‹:
    1. æ ¹æ®modeå‚æ•°é€‰æ‹©åƒç´ ç©ºé—´æˆ–æ½œç©ºé—´æ¨¡å¼
    2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé…ç½®
    3. åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    4. ã€æ½œç©ºé—´ã€‘åŠ è½½VAEæ¨¡å‹
    5. åŠ è½½æµ‹è¯•æ•°æ®
    6. ç”Ÿæˆé¢„æµ‹
       ã€æ½œç©ºé—´ã€‘VAEåˆ†æ‰¹ç¼–ç ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
       ã€æ½œç©ºé—´ã€‘U-Netæ½œç©ºé—´é¢„æµ‹
       ã€æ½œç©ºé—´ã€‘VAEåˆ†æ‰¹è§£ç å›åƒç´ ç©ºé—´
    7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå½’ä¸€åŒ–ç©ºé—´ + ç‰©ç†ç©ºé—´ï¼‰
    8. ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ—¶é—´åºåˆ—å›¾ + ä¸–ç•Œåœ°å›¾å¯¹æ¯”ï¼‰
    9. ä¿å­˜æ‰€æœ‰ç»“æœ
    
âš¡ æ˜¾å­˜ä¼˜åŒ–:
    ä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç ç­–ç•¥ï¼ˆä¸train_latent_unet.pyä¸€è‡´ï¼‰
    - é¿å…ä¸€æ¬¡æ€§å¤„ç†å¤§é‡å›¾åƒå¯¼è‡´æ˜¾å­˜æº¢å‡º
    - é»˜è®¤vae_batch_size=4ï¼Œé€‚åˆ12GB GPU
    - å¯æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ï¼ˆ6GBç”¨2ï¼Œ24GBç”¨8ï¼‰

ğŸ“Š è¾“å‡ºæ–‡ä»¶:
    - prediction_metrics.json: è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
    - y_pred_*.npy: é¢„æµ‹æ•°æ®ï¼ˆå½’ä¸€åŒ– + ç‰©ç†å•ä½ï¼‰
    - y_true_*.npy: çœŸå€¼æ•°æ®
    - timeseries_*.png: æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
    - spatial_comparison_*.png: ä¸–ç•Œåœ°å›¾å¯¹æ¯”å›¾ â­
    - rmse_vs_leadtime_*.png: RMSEéšé¢„æµ‹æ­¥é•¿å˜åŒ–

ğŸ“– ä½¿ç”¨æ–¹æ³•:
    # åƒç´ ç©ºé—´U-Neté¢„æµ‹
    python predict_unet.py --mode pixel \\
        --model-dir outputs/pixel_unet \\
        --time-slice 2020-02-01:2020-02-10
    
    # æ½œç©ºé—´U-Neté¢„æµ‹ï¼ˆæ¨èé…ç½®ï¼‰
    python predict_unet.py --mode latent \\
        --model-dir outputs/latent_unet \\
        --time-slice 2020-02-01:2020-02-10 \\
        --batch-size 32 \\
        --vae-batch-size 4  # æ§åˆ¶æ˜¾å­˜å ç”¨
    
    # æ˜¾å­˜ä¸è¶³æ—¶è°ƒæ•´
    python predict_unet.py --mode latent \\
        --model-dir outputs/latent_unet \\
        --batch-size 16 \\
        --vae-batch-size 2  # å‡å°VAEæ‰¹æ¬¡

ğŸ¯ é¢„æœŸæ•ˆæœ:
    åƒç´ ç©ºé—´U-Net:
        - RMSE: 1-3K
        - ç›¸å…³ç³»æ•°: > 0.995
        - SSIM: > 0.995
    
    æ½œç©ºé—´U-Net:
        - RMSE: 2-5K
        - ç›¸å…³ç³»æ•°: > 0.99
        - SSIM: > 0.99
"""

import argparse
import torch
import numpy as np
import json
import pickle
from pathlib import Path
from tqdm import tqdm

from weatherdiff.unet import WeatherUNet, LatentUNet
from weatherdiff.vae import SDVAEWrapper, RAEWrapper
from weatherdiff.utils import WeatherDataModule, calculate_metrics, format_metrics
from src.visualization import visualize_predictions_improved


def detect_lon_first(data_array):
    """
    åˆ¤æ–­æ•°æ®çš„ç©ºé—´ç»´åº¦é¡ºåºæ˜¯å¦ä¸º (lon, lat)

    Args:
        data_array: xarray DataArray

    Returns:
        True  -> ç©ºé—´é¡ºåºä¸º (lon, lat)
        False -> ç©ºé—´é¡ºåºä¸º (lat, lon)
        None  -> æ— æ³•åˆ¤æ–­ï¼ˆç¼ºå°‘ç»´åº¦åç§°ï¼‰
    """
    dims = list(getattr(data_array, "dims", []))
    if not dims:
        return None

    lat_dim = next((dim for dim in dims if "lat" in dim.lower()), None)
    lon_dim = next((dim for dim in dims if "lon" in dim.lower()), None)

    if lat_dim is None or lon_dim is None:
        return None

    lat_idx = dims.index(lat_dim)
    lon_idx = dims.index(lon_dim)

    return lon_idx < lat_idx


def encode_in_batches(vae_wrapper, images, vae_batch_size=4, device="cuda"):
    """
    åˆ†æ‰¹ç¼–ç å›¾åƒåˆ°æ½œç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰

    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        images: (N, C, H, W) å›¾åƒtensor (åœ¨CPUä¸Š)
        vae_batch_size: VAEç¼–ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡

    Returns:
        latents: (N, 4, H//8, W//8) æ½œå‘é‡
    """
    N = images.shape[0]
    latent_list = []

    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = images[i:end_idx].to(device)
        latent_batch = vae_wrapper.encode(batch)
        latent_list.append(latent_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜

        # æ¸…ç†æ˜¾å­˜
        del batch, latent_batch
        torch.cuda.empty_cache()

    # åˆå¹¶æ‰€æœ‰batch
    latents = torch.cat(latent_list, dim=0).to(device)
    return latents


def decode_in_batches(vae_wrapper, latents, vae_batch_size=4, device="cuda"):
    """
    åˆ†æ‰¹è§£ç æ½œå‘é‡åˆ°åƒç´ ç©ºé—´ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰

    Args:
        vae_wrapper: VAEåŒ…è£…å™¨
        latents: (N, 4, H//8, W//8) æ½œå‘é‡tensor (åœ¨CPUä¸Š)
        vae_batch_size: VAEè§£ç æ—¶çš„å­æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡

    Returns:
        images: (N, 3, H, W) å›¾åƒ
    """
    N = latents.shape[0]
    image_list = []

    for i in range(0, N, vae_batch_size):
        end_idx = min(i + vae_batch_size, N)
        batch = latents[i:end_idx].to(device)
        image_batch = vae_wrapper.decode(batch)
        image_list.append(image_batch.cpu())  # ç«‹å³ç§»å›CPUé‡Šæ”¾æ˜¾å­˜

        # æ¸…ç†æ˜¾å­˜
        del batch, image_batch
        torch.cuda.empty_cache()

    # åˆå¹¶æ‰€æœ‰batch
    images = torch.cat(image_list, dim=0).to(device)
    return images


def predict_pixel_unet(args):
    """åƒç´ ç©ºé—´U-Neté¢„æµ‹"""

    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "=" * 80)
    print("åƒç´ ç©ºé—´U-Neté¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)

    config_path = model_dir / "config.json"
    with open(config_path, "r") as f:
        config = json.load(f)

    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")

    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / "normalizer_stats.pkl"
    with open(normalizer_path, "rb") as f:
        normalizer_data = pickle.load(f)

    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")

    # ========================================================================
    # Step 2: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½æ•°æ®")
    print("-" * 80)

    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from torch.utils.data import DataLoader
    from weatherdiff.utils import (
        prepare_weather_data,
        WeatherSequenceDataset,
        Normalizer,
    )

    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)

    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(":")
    ds = ds.sel(time=slice(start, end))

    # è·å–å˜é‡æ•°æ®
    variable_da = ds[config["variable"]]
    lon_first_flag = detect_lon_first(variable_da)
    if lon_first_flag is not None:
        config["_spatial_lon_first"] = lon_first_flag
        orientation_desc = (
            "Longitude-First (lon->lat)"
            if lon_first_flag
            else "Latitude-First (lat->lon)"
        )
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: {orientation_desc} | dims={variable_da.dims}")
    else:
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: æœªæ£€æµ‹åˆ°çº¬/ç»åº¦åç§° | dims={variable_da.dims}")
    data = variable_da.values  # (Time, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")

    # è·å–target_sizeï¼ˆå¦‚æœæœ‰ï¼‰
    target_size = None
    if "target_size" in config and config["target_size"]:
        if isinstance(config["target_size"], str):
            target_size = tuple(map(int, config["target_size"].split(",")))
        else:
            target_size = tuple(config["target_size"])

    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(
        data, n_channels=config["n_channels"], target_size=target_size
    )
    print(f"å¤„ç†å shape: {data.shape}")
    if target_size:
        print(f"  å›¾åƒå°ºå¯¸: {target_size}")
        # éªŒè¯æ•°æ®å°ºå¯¸æ˜¯å¦ä¸target_sizeä¸€è‡´
        _, _, data_H, data_W = data.shape
        if data_H != target_size[0] or data_W != target_size[1]:
            raise ValueError(
                f"æ•°æ®å°ºå¯¸ä¸åŒ¹é…ï¼š\n"
                f"  æ•°æ®åŠ è½½åçš„å°ºå¯¸: ({data_H}, {data_W})\n"
                f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
                f"  å¯èƒ½åŸå› ï¼šprepare_weather_dataæœªæ­£ç¡®resizeåˆ°target_size\n"
                f"  è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥prepare_weather_dataçš„target_sizeå‚æ•°æ˜¯å¦æ­£ç¡®ä¼ é€’"
            )

    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config["normalization"])
    normalizer.load_stats(normalizer_data["stats"])
    data = normalizer.transform(data, name=config["variable"])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")

    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, config["input_length"], config["output_length"]
    )

    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True,
    )

    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")

    # ========================================================================
    # Step 3: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ¨¡å‹")
    print("-" * 80)

    # è·å–æ•°æ®å½¢çŠ¶ä¿¡æ¯
    sample_input, sample_output = full_dataset[0]
    T_in, C, H, W = sample_input.shape
    T_out = sample_output.shape[0]

    in_channels = T_in * C
    out_channels = T_out * C

    model = WeatherUNet(
        in_channels=in_channels,
        out_channels=out_channels,
        base_channels=config["base_channels"],
        depth=config["depth"],
    )

    checkpoint_path = model_dir / "best_model.pt"
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(args.device)
    model.eval()

    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ========================================================================
    # Step 4: é¢„æµ‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: ç”Ÿæˆé¢„æµ‹")
    print("-" * 80)

    all_predictions = []
    all_targets = []
    all_inputs = []

    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc="é¢„æµ‹ä¸­"):
            inputs = inputs.to(args.device)
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]

            # å±•å¹³æ—¶é—´ç»´åº¦
            inputs_flat = inputs.reshape(B, T_in * C, H, W)
            outputs = model(inputs_flat)
            outputs = outputs.reshape(B, T_out, C, H, W)

            all_predictions.append(outputs.cpu().numpy())
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())

    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)

    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")

    return y_pred, y_true, normalizer, config, output_dir


def predict_latent_unet(args):
    """æ½œç©ºé—´U-Neté¢„æµ‹"""

    model_dir = Path(args.model_dir)
    output_dir = Path(args.output_dir) if args.output_dir else model_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "=" * 80)
    print("æ½œç©ºé—´U-Neté¢„æµ‹")
    print("=" * 80)
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"é¢„æµ‹æ—¶é—´: {args.time_slice}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # ========================================================================
    # Step 1: åŠ è½½é…ç½®
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 1: åŠ è½½é…ç½®")
    print("-" * 80)

    config_path = model_dir / "config.json"
    with open(config_path, "r") as f:
        config = json.load(f)

    print(f"âœ“ åŠ è½½é…ç½®: {config_path}")
    print(f"  è¾“å…¥åºåˆ—é•¿åº¦: {config['input_length']}")
    print(f"  è¾“å‡ºåºåˆ—é•¿åº¦: {config['output_length']}")
    print(f"  å½’ä¸€åŒ–æ–¹æ³•: {config['normalization']}")

    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    normalizer_path = model_dir / "normalizer_stats.pkl"
    with open(normalizer_path, "rb") as f:
        normalizer_data = pickle.load(f)

    print(f"âœ“ åŠ è½½å½’ä¸€åŒ–å‚æ•°: {normalizer_path}")

    # ========================================================================
    # Step 2: åŠ è½½VAE
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 2: åŠ è½½VAE")
    print("-" * 80)

    # æ£€æŸ¥VAEç±»å‹
    vae_type = normalizer_data.get("vae_type", "sd")  # é»˜è®¤SD VAE
    if vae_type == "sd":
        vae_model_id = config.get(
            "vae_model_id",
            normalizer_data.get("vae_model_id", "stable-diffusion-v1-5"),
        )
        vae_train_mode = config.get(
            "vae_train_mode",
            normalizer_data.get("vae_train_mode", "pretrained"),
        )
        vae_pretrained_path = config.get(
            "vae_pretrained_path",
            normalizer_data.get("vae_pretrained_path", None),
        )
        freeze_vae = config.get(
            "freeze_vae",
            normalizer_data.get("freeze_vae", True),
        )

        print(f"ä½¿ç”¨Stable Diffusion VAE: {vae_model_id}")
        print(f"  VAEè®­ç»ƒæ¨¡å¼: {vae_train_mode}")
        if vae_pretrained_path:
            print(f"  é¢„è®­ç»ƒæƒé‡è·¯å¾„: {vae_pretrained_path}")
        print(f"  VAEå†»ç»“: {freeze_vae}")

        vae_wrapper = SDVAEWrapper(
            model_id=vae_model_id,
            device=args.device,
            train_mode=vae_train_mode,
            pretrained_path=vae_pretrained_path,
            freeze_vae=freeze_vae,
        )
        latent_channels = 4
    elif vae_type == "rae":
        print(
            f"ä½¿ç”¨RAE: encoder={normalizer_data.get('rae_encoder_cls', 'SigLIP2wNorm')}"
        )
        # æ„å»ºencoder_params
        encoder_params = {}
        encoder_cls = normalizer_data.get("rae_encoder_cls", "SigLIP2wNorm")
        encoder_config_path = normalizer_data.get(
            "rae_encoder_config_path", "google/siglip2-base-patch16-256"
        )

        if encoder_cls == "Dinov2withNorm":
            encoder_params = {"dinov2_path": encoder_config_path, "normalize": True}
        elif encoder_cls == "SigLIP2wNorm":
            encoder_params = {"model_name": encoder_config_path}
        elif encoder_cls == "MAEwNorm":
            encoder_params = {"model_name": encoder_config_path}

        vae_wrapper = RAEWrapper(
            encoder_cls=encoder_cls,
            encoder_config_path=encoder_config_path,
            encoder_input_size=normalizer_data.get("rae_encoder_input_size", 256),
            encoder_params=encoder_params,
            decoder_config_path=normalizer_data.get(
                "rae_decoder_config_path", "facebook/vit-mae-base"
            ),
            decoder_patch_size=normalizer_data.get("rae_decoder_patch_size", 16),
            pretrained_decoder_path=normalizer_data.get(
                "rae_pretrained_decoder_path", None
            ),
            normalization_stat_path=normalizer_data.get(
                "rae_normalization_stat_path", None
            ),
            device=args.device,
            freeze_encoder=normalizer_data.get("freeze_encoder", True),
            freeze_decoder=normalizer_data.get("freeze_decoder", False),
        )
        # è·å–latent_channelsï¼ˆéœ€è¦å…ˆæœ‰target_sizeï¼Œæš‚æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        # åé¢ä¼šæ ¹æ®å®é™…target_sizeæ›´æ–°
        latent_channels = config.get("latent_channels", None)
    else:
        raise ValueError(f"Unknown VAE type: {vae_type}")

    print(f"âœ“ VAEåŠ è½½å®Œæˆ")

    # ========================================================================
    # Step 3: åŠ è½½æ•°æ®ï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²æ•°æ®ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 3: åŠ è½½æ•°æ®")
    print("-" * 80)

    # è§£ætarget_size
    target_size = tuple(map(int, config["target_size"].split(",")))

    # å¦‚æœä½¿ç”¨RAEï¼Œæ›´æ–°latent_channels
    if vae_type == "rae" and latent_channels is None:
        latent_shape = vae_wrapper.get_latent_shape((3, target_size[0], target_size[1]))
        latent_channels = latent_shape[0]

    # ç›´æ¥åŠ è½½æ•°æ®ï¼Œä¸ä½¿ç”¨WeatherDataModuleçš„åˆ†å‰²é€»è¾‘
    import xarray as xr
    from torch.utils.data import DataLoader
    from weatherdiff.utils import (
        prepare_weather_data,
        WeatherSequenceDataset,
        Normalizer,
    )

    print(f"åŠ è½½æ•°æ®: {args.data_path}")
    ds = xr.open_zarr(args.data_path)

    # æ—¶é—´åˆ‡ç‰‡
    start, end = args.time_slice.split(":")
    ds = ds.sel(time=slice(start, end))

    # è·å–å˜é‡æ•°æ®
    variable_da = ds[config["variable"]]
    lon_first_flag = detect_lon_first(variable_da)
    if lon_first_flag is not None:
        config["_spatial_lon_first"] = lon_first_flag
        orientation_desc = (
            "Longitude-First (lon->lat)"
            if lon_first_flag
            else "Latitude-First (lat->lon)"
        )
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: {orientation_desc} | dims={variable_da.dims}")
    else:
        print(f"  ç©ºé—´ç»´åº¦é¡ºåº: æœªæ£€æµ‹åˆ°çº¬/ç»åº¦åç§° | dims={variable_da.dims}")
    data = variable_da.values  # (Time, H, W)
    print(f"åŸå§‹æ•°æ® shape: {data.shape}")
    print(f"æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    print(f"æ—¶é—´èŒƒå›´: {start} è‡³ {end}")

    # å‡†å¤‡ä¸ºå›¾åƒæ ¼å¼
    data = prepare_weather_data(data, n_channels=3, target_size=target_size)
    print(f"å¤„ç†å shape: {data.shape}")
    print(f"  å›¾åƒå°ºå¯¸: {target_size}")

    # éªŒè¯æ•°æ®å°ºå¯¸æ˜¯å¦ä¸target_sizeä¸€è‡´
    _, _, data_H, data_W = data.shape
    if data_H != target_size[0] or data_W != target_size[1]:
        raise ValueError(
            f"æ•°æ®å°ºå¯¸ä¸åŒ¹é…ï¼š\n"
            f"  æ•°æ®åŠ è½½åçš„å°ºå¯¸: ({data_H}, {data_W})\n"
            f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
            f"  å¯èƒ½åŸå› ï¼šprepare_weather_dataæœªæ­£ç¡®resizeåˆ°target_size\n"
            f"  è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥prepare_weather_dataçš„target_sizeå‚æ•°æ˜¯å¦æ­£ç¡®ä¼ é€’"
        )

    # è·å–latent shape
    if vae_type == "rae":
        latent_shape = vae_wrapper.get_latent_shape((3, target_size[0], target_size[1]))
        latent_channels, latent_h, latent_w = latent_shape
        print(f"  æ½œå‘é‡å°ºå¯¸: ({latent_channels}, {latent_h}, {latent_w})")
    else:
        print(
            f"  æ½œå‘é‡å°ºå¯¸: ({latent_channels}, {target_size[0]//8}, {target_size[1]//8})"
        )
        latent_h = target_size[0] // 8
        latent_w = target_size[1] // 8

    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‚æ•°ï¼‰
    normalizer = Normalizer(method=config["normalization"])
    normalizer.load_stats(normalizer_data["stats"])
    data = normalizer.transform(data, name=config["variable"])
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")

    # åˆ›å»ºå®Œæ•´çš„åºåˆ—æ•°æ®é›†ï¼ˆä¸åˆ†å‰²ï¼‰
    full_dataset = WeatherSequenceDataset(
        data, config["input_length"], config["output_length"]
    )

    test_loader = DataLoader(
        full_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True,
    )

    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼šä¸åˆ†å‰²ï¼‰")
    print(f"  æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(test_loader)}")

    # ========================================================================
    # Step 4: åŠ è½½æ¨¡å‹
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 4: åŠ è½½æ¨¡å‹")
    print("-" * 80)

    # è·å–æ•°æ®å½¢çŠ¶ä¿¡æ¯
    sample_input, _ = full_dataset[0]
    T_in = sample_input.shape[0]
    T_out = config["output_length"]

    # è·å–latent_channels
    if "latent_channels" in config:
        latent_channels = config["latent_channels"]
    elif vae_type == "rae":
        latent_shape = vae_wrapper.get_latent_shape((3, target_size[0], target_size[1]))
        latent_channels = latent_shape[0]
    else:
        latent_channels = 4  # SD VAEå›ºå®šä¸º4

    model = LatentUNet(
        input_length=config["input_length"],
        output_length=config["output_length"],
        latent_channels=latent_channels,
        base_channels=config["base_channels"],
        depth=config["depth"],
    )

    checkpoint_path = model_dir / "best_model.pt"
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(args.device)
    model.eval()

    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ: {checkpoint_path}")
    print(f"  è®­ç»ƒepoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ========================================================================
    # Step 5: é¢„æµ‹ï¼ˆæ½œç©ºé—´ -> åƒç´ ç©ºé—´ï¼‰
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 5: ç”Ÿæˆé¢„æµ‹ (ä½¿ç”¨VAEåˆ†æ‰¹ç¼–ç /è§£ç )")
    print("-" * 80)

    vae_batch_size = args.vae_batch_size
    print(f"  VAE batch size: {vae_batch_size} (æ§åˆ¶æ˜¾å­˜å ç”¨)")

    all_predictions = []
    all_targets = []
    all_inputs = []

    with torch.no_grad():
        for inputs, targets in tqdm(test_loader, desc="é¢„æµ‹ä¸­(æ½œç©ºé—´)"):
            B, T_in, C, H, W = inputs.shape
            T_out = targets.shape[1]

            # ç¼–ç åˆ°æ½œç©ºé—´ï¼ˆåˆ†æ‰¹å¤„ç†é¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            inputs_flat = inputs.reshape(B * T_in, C, H, W)
            latent_inputs = encode_in_batches(
                vae_wrapper, inputs_flat, vae_batch_size, args.device
            )

            # è·å–latent shape
            if vae_type == "rae":
                latent_shape = vae_wrapper.get_latent_shape((C, H, W))
                latent_channels_batch, latent_h_batch, latent_w_batch = latent_shape
            else:
                latent_channels_batch = 4
                latent_h_batch = H // 8
                latent_w_batch = W // 8

            latent_inputs = latent_inputs.reshape(
                B, T_in, latent_channels_batch, latent_h_batch, latent_w_batch
            )

            # æ½œç©ºé—´é¢„æµ‹ï¼ˆLatentUNetæœŸæœ›5ç»´è¾“å…¥ï¼‰
            latent_outputs = model(latent_inputs)

            # è§£ç å›åƒç´ ç©ºé—´ï¼ˆåˆ†æ‰¹å¤„ç†é¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            latent_outputs_flat = latent_outputs.reshape(
                B * T_out, latent_channels_batch, latent_h_batch, latent_w_batch
            )
            outputs = decode_in_batches(
                vae_wrapper, latent_outputs_flat.cpu(), vae_batch_size, args.device
            )

            # decode_in_batchesè¿”å›çš„æ˜¯ (B*T_out, C, H, W)
            _, _, decoded_H, decoded_W = outputs.shape
            outputs = outputs.reshape(B, T_out, C, decoded_H, decoded_W)

            # ä¸¥æ ¼éªŒè¯ï¼šè§£ç åçš„å°ºå¯¸å¿…é¡»ç­‰äºtarget_sizeï¼ˆè®­ç»ƒæ—¶çš„å°ºå¯¸ï¼‰
            # å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œè¯´æ˜é¢„æµ‹æ—¶çš„æ•°æ®åŠ è½½æˆ–VAEé…ç½®æœ‰é—®é¢˜ï¼Œç›´æ¥æŠ¥é”™
            if decoded_H != target_size[0] or decoded_W != target_size[1]:
                raise ValueError(
                    f"ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š\n"
                    f"  VAEè§£ç è¾“å‡ºå°ºå¯¸: ({decoded_H}, {decoded_W})\n"
                    f"  è®­ç»ƒæ—¶target_size: {target_size}\n"
                    f"  é¢„æµ‹æ—¶è¾“å…¥å°ºå¯¸: ({H}, {W})\n"
                    f"  å¯èƒ½åŸå› ï¼š\n"
                    f"    1. é¢„æµ‹æ—¶æ•°æ®åŠ è½½æœªä½¿ç”¨æ­£ç¡®çš„target_size\n"
                    f"    2. VAEé…ç½®ä¸è®­ç»ƒæ—¶ä¸ä¸€è‡´ï¼ˆç‰¹åˆ«æ˜¯RAEçš„decoderé…ç½®ï¼‰\n"
                    f"    3. æ•°æ®åŠ è½½åæœªæ­£ç¡®resizeåˆ°target_size\n"
                    f"  è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿é¢„æµ‹æ—¶ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„target_sizeå’ŒVAEé…ç½®"
                )

            all_predictions.append(outputs.cpu().numpy())
            all_targets.append(targets.numpy())
            all_inputs.append(inputs.cpu().numpy())

    y_pred = np.concatenate(all_predictions, axis=0)
    y_true = np.concatenate(all_targets, axis=0)
    X = np.concatenate(all_inputs, axis=0)

    print(f"âœ“ é¢„æµ‹å®Œæˆ")
    print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
    print(f"  é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
    print(f"  çœŸå€¼å½¢çŠ¶: {y_true.shape}")

    return y_pred, y_true, normalizer, config, output_dir


def main():
    parser = argparse.ArgumentParser(description="U-Netç»Ÿä¸€é¢„æµ‹è„šæœ¬")

    # æ¨¡å¼é€‰æ‹©
    parser.add_argument(
        "--mode",
        type=str,
        required=True,
        choices=["pixel", "latent"],
        help="é¢„æµ‹æ¨¡å¼: pixel=åƒç´ ç©ºé—´, latent=æ½œç©ºé—´",
    )

    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        "--model-dir",
        type=str,
        required=True,
        help="æ¨¡å‹ç›®å½•ï¼ˆåŒ…å«best_model.ptå’Œconfig.jsonï¼‰",
    )

    # æ•°æ®å‚æ•°
    parser.add_argument(
        "--data-path",
        type=str,
        default="gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr",
        help="æ•°æ®è·¯å¾„",
    )
    parser.add_argument(
        "--time-slice", type=str, default="2020-01-01:2020-12-31", help="é¢„æµ‹æ—¶é—´èŒƒå›´"
    )

    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--output-dir", type=str, default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹ç›®å½•ï¼‰"
    )
    parser.add_argument("--batch-size", type=int, default=32, help="é¢„æµ‹æ‰¹æ¬¡å¤§å°")
    parser.add_argument(
        "--vae-batch-size",
        type=int,
        default=4,
        help="VAEç¼–ç /è§£ç æ‰¹æ¬¡å¤§å°ï¼ˆä»…latentæ¨¡å¼ï¼Œæ§åˆ¶æ˜¾å­˜å ç”¨ï¼‰",
    )

    # å…¶ä»–å‚æ•°
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="è®¾å¤‡",
    )

    args = parser.parse_args()

    # ========================================================================
    # æ ¹æ®æ¨¡å¼é€‰æ‹©é¢„æµ‹æ–¹æ³•
    # ========================================================================
    if args.mode == "pixel":
        y_pred, y_true, normalizer, config, output_dir = predict_pixel_unet(args)
    else:
        y_pred, y_true, normalizer, config, output_dir = predict_latent_unet(args)

    # ========================================================================
    # Step 6: åå½’ä¸€åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 6: è¯„ä¼°å’Œåå½’ä¸€åŒ–")
    print("-" * 80)

    # å½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡
    print("\nå½’ä¸€åŒ–ç©ºé—´çš„æŒ‡æ ‡:")
    metrics_norm = calculate_metrics(y_pred, y_true, ensemble=False)
    print(format_metrics(metrics_norm))

    # åå½’ä¸€åŒ–åˆ°ç‰©ç†å•ä½
    variable = config["variable"]
    C = y_pred.shape[2]
    H = y_pred.shape[3]
    W = y_pred.shape[4]

    y_pred_flat = y_pred.reshape(-1, C, H, W)
    y_true_flat = y_true.reshape(-1, C, H, W)

    y_pred_phys = normalizer.inverse_transform(y_pred_flat, name=variable)
    y_true_phys = normalizer.inverse_transform(y_true_flat, name=variable)

    y_pred_phys = y_pred_phys.reshape(y_pred.shape)
    y_true_phys = y_true_phys.reshape(y_true.shape)

    print("\nâœ“ åå½’ä¸€åŒ–å®Œæˆ")
    print(f"  é¢„æµ‹èŒƒå›´: [{y_pred_phys.min():.2f}, {y_pred_phys.max():.2f}] K")
    print(f"  çœŸå€¼èŒƒå›´: [{y_true_phys.min():.2f}, {y_true_phys.max():.2f}] K")

    # ç‰©ç†ç©ºé—´çš„æŒ‡æ ‡
    print("\nç‰©ç†ç©ºé—´çš„æŒ‡æ ‡ (åŸå§‹å°ºåº¦):")
    metrics_phys = calculate_metrics(y_pred_phys, y_true_phys, ensemble=False)
    print(format_metrics(metrics_phys))

    # è®¡ç®—æ¯ä¸ªlead timeçš„RMSE
    print("\næ¯ä¸ªlead timeçš„RMSE:")
    T_out = y_pred_phys.shape[1]
    rmse_per_leadtime = {}
    for t in range(T_out):
        y_pred_t = y_pred_phys[:, t, :, :, :]  # (N, C, H, W)
        y_true_t = y_true_phys[:, t, :, :, :]
        rmse_t = np.sqrt(np.mean((y_pred_t - y_true_t) ** 2))
        rmse_per_leadtime[f"rmse_step_{t+1}"] = float(rmse_t)
        print(f"  Step {t+1} ({(t+1)*6}h): {rmse_t:.4f} K")

    # ========================================================================
    # Step 7: ä¿å­˜ç»“æœ
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 7: ä¿å­˜ç»“æœ")
    print("-" * 80)

    # ä¿å­˜æŒ‡æ ‡
    metrics_all = {
        "mode": args.mode,
        "normalized_space": {k: float(v) for k, v in metrics_norm.items()},
        "physical_space": {k: float(v) for k, v in metrics_phys.items()},
        "physical_space_rmse_per_leadtime": rmse_per_leadtime,
        "time_slice": args.time_slice,
        "n_samples": int(y_pred.shape[0]),
    }

    metrics_path = output_dir / "prediction_metrics.json"
    with open(metrics_path, "w") as f:
        json.dump(metrics_all, f, indent=2)
    print(f"âœ“ æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")

    # ä¿å­˜é¢„æµ‹æ•°æ®
    pred_dir = output_dir / "predictions_data"
    pred_dir.mkdir(exist_ok=True)
    np.save(pred_dir / "y_test_pred_norm.npy", y_pred)
    np.save(pred_dir / "y_test_norm.npy", y_true)
    np.save(pred_dir / "y_test.npy", y_true_phys)  # çœŸå€¼
    np.save(pred_dir / "y_test_pred.npy", y_pred_phys)  # é¢„æµ‹å€¼
    print(f"âœ“ é¢„æµ‹æ•°æ®å·²ä¿å­˜: {pred_dir}/y_*.npy")

    # ========================================================================
    # Step 8: ç”Ÿæˆå¯è§†åŒ–
    # ========================================================================
    print("\n" + "-" * 80)
    print("Step 8: ç”Ÿæˆå¯è§†åŒ–")
    print("-" * 80)

    # è·å–ç©ºé—´åæ ‡
    import xarray as xr

    ds = xr.open_zarr(args.data_path)

    spatial_coords = None
    lon_first_flag = config.get("_spatial_lon_first")
    if hasattr(ds, "latitude") and hasattr(ds, "longitude"):
        lat_values = ds.latitude.values
        lon_values = ds.longitude.values

        # è·å–é¢„æµ‹æ•°æ®çš„å®é™…ç©ºé—´å½¢çŠ¶
        # y_pred_phys shape: (N, T, C, H, W)
        actual_H = y_pred_phys.shape[3]
        actual_W = y_pred_phys.shape[4]

        print(f"\næ£€æŸ¥ç©ºé—´åæ ‡:")
        print(f"  æ•°æ®é›†åæ ‡: lat={len(lat_values)}, lon={len(lon_values)}")
        print(f"  é¢„æµ‹æ•°æ®å½¢çŠ¶: H={actual_H}, W={actual_W}")

        orientation_handled = False
        if lon_first_flag is True:
            print("  æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®ä¸º Longitude-Firstï¼ˆlon->latï¼‰ï¼Œä¸ºå¯è§†åŒ–è½¬ç½®ä¸€æ¬¡")
            y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
            y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))
            orientation_handled = True
            actual_H = y_pred_phys.shape[3]
            actual_W = y_pred_phys.shape[4]
            print(f"  è½¬ç½®å: H={actual_H}(lat), W={actual_W}(lon)")
        elif lon_first_flag is False:
            print("  æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®ä¸º Latitude-Firstï¼ˆlat->lonï¼‰ï¼Œæ— éœ€é¢å¤–å¤„ç†")
            orientation_handled = True
        else:
            print("  æœªèƒ½ä»é…ç½®ç¡®å®šç©ºé—´é¡ºåºï¼Œå°è¯•æ ¹æ®åæ ‡é•¿åº¦æ¨æ–­...")

        if not orientation_handled:
            # ä½¿ç”¨åæ ‡é•¿åº¦è¿›è¡Œå›é€€æ¨æ–­
            if len(lon_values) == actual_H and len(lat_values) == actual_W:
                print(f"  âœ“ åæ ‡åŒ¹é… (ERA5æ ¼å¼: H={actual_H}(lon), W={actual_W}(lat))")
                print(f"  è½¬ç½®ç©ºé—´ç»´åº¦ä»¥é€‚é…visualization (H<->W)")

                y_pred_phys = np.transpose(y_pred_phys, (0, 1, 2, 4, 3))
                y_true_phys = np.transpose(y_true_phys, (0, 1, 2, 4, 3))
                actual_H = y_pred_phys.shape[3]
                actual_W = y_pred_phys.shape[4]
                print(f"  è½¬ç½®å: H={actual_H}(lat), W={actual_W}(lon)")
            elif len(lat_values) == actual_H and len(lon_values) == actual_W:
                print(f"  âœ“ åæ ‡åŒ¹é… (æ ‡å‡†æ ¼å¼: H={actual_H}(lat), W={actual_W}(lon))")
            else:
                print(
                    f"  âš  åæ ‡ç»´åº¦ä¸åŒ¹é… (lat:{len(lat_values)}, lon:{len(lon_values)} vs H:{actual_H}, W:{actual_W})"
                )

        # æ ¹æ®æœ€ç»ˆçš„ç©ºé—´å½¢çŠ¶é€‰æ‹©åæ ‡
        if (
            len(lat_values) == y_pred_phys.shape[3]
            and len(lon_values) == y_pred_phys.shape[4]
        ):
            spatial_coords = {
                "lat": lat_values,
                "lon": lon_values,
            }
        else:
            # å°ºå¯¸å®Œå…¨ä¸åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤åæ ‡
            print(
                f"  ä½¿ç”¨é»˜è®¤åæ ‡ç”Ÿæˆå¯è§†åŒ– ({y_pred_phys.shape[3]}x{y_pred_phys.shape[4]}) ..."
            )
            spatial_coords = {
                "lat": np.linspace(-90, 90, y_pred_phys.shape[3]),
                "lon": np.linspace(0, 360, y_pred_phys.shape[4]),
            }

    # ç”Ÿæˆå¯è§†åŒ–
    # æ³¨æ„ï¼šWeatherDiffä½¿ç”¨minmaxå½’ä¸€åŒ–ï¼ˆ[-1,1]ï¼‰ï¼Œä¸ä¼ ç»Ÿæ¨¡å‹çš„zscoreä¸åŒ
    # è¿™é‡Œä¼ é€’å·²ç»åå½’ä¸€åŒ–çš„ç‰©ç†å€¼æ•°æ®ï¼Œnorm_params=None
    # å¯è§†åŒ–å‡½æ•°ä¼šç”Ÿæˆtimeseries_overallï¼ˆç‰©ç†å€¼ï¼‰ï¼Œä½†ä¸ä¼šç”Ÿæˆtimeseries_physical
    # ï¼ˆå› ä¸ºWeatherDiffçš„å½’ä¸€åŒ–æ–¹å¼ä¸å¯è§†åŒ–å‡½æ•°é¢„æœŸä¸å…¼å®¹ï¼‰
    visualize_predictions_improved(
        y_true_phys,  # y_test (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        y_pred_phys,  # y_test_pred (ç‰©ç†å€¼æ•°æ®ï¼Œå¯èƒ½å·²è½¬ç½®)
        metrics_phys,  # test_metrics (ç‰©ç†ç©ºé—´æŒ‡æ ‡)
        [variable],  # variables
        f"{args.mode}_unet",  # model_name
        output_dir,  # output_dir
        "spatial",  # data_format
        norm_params=None,  # norm_params (ä¸æä¾›ï¼Œå› ä¸ºå½’ä¸€åŒ–æ–¹å¼ä¸åŒ)
        spatial_coords=spatial_coords,  # spatial_coords
    )

    print(f"âœ“ å¯è§†åŒ–å·²ç”Ÿæˆ")
    print(f"  - timeseries_overall_{variable}.png (ç‰©ç†å€¼)")
    print(
        f"  - timeseries_physical_{variable}.png (æœªç”Ÿæˆï¼Œå› ä¸ºå·²ä½¿ç”¨ç‰©ç†å€¼ç»˜åˆ¶overall)"
    )
    print(f"  - leadtime_independent_{variable}.png")
    print(f"  - rmse_vs_leadtime_{variable}.png")
    print(f"  - spatial_comparison_{variable}.png")

    # ========================================================================
    # æ€»ç»“
    # ========================================================================
    print("\n" + "=" * 80)
    print("é¢„æµ‹å®Œæˆ!")
    print("=" * 80)

    print(f"\næ¨¡å¼: {args.mode.upper()}")
    print(f"æ€»ç»“ (ç‰©ç†ç©ºé—´):")
    print(f"  æ ·æœ¬æ•°: {y_pred.shape[0]}")
    print(f"  RMSE: {metrics_phys['rmse']:.4f} K")
    print(f"  MAE: {metrics_phys['mae']:.4f} K")
    print(f"  ç›¸å…³ç³»æ•°: {metrics_phys['correlation']:.4f}")
    print(f"  SSIM: {metrics_phys['ssim']:.4f}")

    print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"  - prediction_metrics.json: è¯¦ç»†æŒ‡æ ‡")
    print(f"  - y_pred_*.npy: é¢„æµ‹æ•°æ®")
    print(f"  - *.png: å¯è§†åŒ–å›¾ç‰‡")

    # æ€§èƒ½è¯„ä»·
    if metrics_phys["rmse"] < 3.0:
        print("\nâœ… é¢„æµ‹æ•ˆæœä¼˜ç§€ï¼")
    elif metrics_phys["rmse"] < 5.0:
        print("\nâœ… é¢„æµ‹æ•ˆæœè‰¯å¥½ï¼")
    elif metrics_phys["rmse"] < 10.0:
        print("\nâš ï¸  é¢„æµ‹æ•ˆæœä¸€èˆ¬")
    else:
        print("\nâš ï¸  é¢„æµ‹æ•ˆæœè¾ƒå·®ï¼Œå»ºè®®:")
        print("  1. å¢åŠ è®­ç»ƒæ•°æ®é‡")
        print("  2. å¢åŠ è®­ç»ƒè½®æ•°")
        print("  3. è°ƒæ•´æ¨¡å‹å‚æ•°")


if __name__ == "__main__":
    main()
